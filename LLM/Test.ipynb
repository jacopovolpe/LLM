{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERAZIONE DI DOMANDE ATTINENTI AL CONTESTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JV_GEMINI_TOKEN = \"AIzaSyArDcTFUTzztpgCIlogXSYQwBhUieZxv7Y\"\n",
    "RS_GEMINI_TOKEN = \"AIzaSyAS0kVBJkyFyosoCwqAQyJM0ElyKEzrmgM\"\n",
    "VM_GEMINI_TOKEN = \"AIzaSyD22Kr3nfSrvkE45KJlbIZHLuTA_cYuBYM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_sections(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    sections = re.split(r'<----------section---------->', text)\n",
    "    \n",
    "    sections = [section.strip() for section in sections if section.strip()]\n",
    "    \n",
    "    return sections\n",
    "\n",
    "file_path = \"data/3Steps_6Marzo2025.txt\"  \n",
    "sections = extract_sections(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "\n",
    "TOKENS = [ VM_GEMINI_TOKEN, JV_GEMINI_TOKEN, RS_GEMINI_TOKEN]\n",
    "current_token_index = 0\n",
    "\n",
    "def call_llm(prompt, token):\n",
    "    genai.configure(api_key=token)\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "question_data = []\n",
    "\n",
    "for section_index, section in enumerate(tqdm(sections, desc=\"Generating Questions\"), start=1):\n",
    "    \n",
    "    prompt = (\n",
    "        \"generate 5 questions based on the following text: \\n\\n\"\n",
    "        f\"{section}\\n\\n\\n\"\n",
    "        \"separate the questions with separator <----------question---------->\"\n",
    "        \"give me only the questions separated by a row and the separator <----------question---------->\"\n",
    "        \"not add any other text or information like answers or context or enumeration\"\n",
    "    )\n",
    "    \n",
    "    response = call_llm(prompt, TOKENS[current_token_index])\n",
    "    questions = response.split(\"<----------question---------->\")\n",
    "    \n",
    "    for question in questions:\n",
    "        if question.strip():  # Evita di salvare stringhe vuote\n",
    "            question_data.append({\"section_index\": section_index, \"question\": question.strip()})\n",
    "    \n",
    "    cont += 1\n",
    "    if cont % 3 == 0:\n",
    "        tempo_casuale_ms = random.randint(5000, 10000) / 1000 \n",
    "        time.sleep(tempo_casuale_ms)\n",
    "        current_token_index = (current_token_index + 1) % len(TOKENS)  #token prossimo nella coda circolare\n",
    "    tempo_casuale_ms = random.randint(4000, 7500) / 1000 \n",
    "    time.sleep(tempo_casuale_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"data/questions/6Marzo2025__ALL.json\"\n",
    "\n",
    "import json\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(question_data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from Assistant import Assistant\n",
    "\n",
    "# Impostazione directory risultati\n",
    "dir_risultati = \"data/questions/response_13Marzo2025\"\n",
    "os.makedirs(dir_risultati, exist_ok=True)\n",
    "\n",
    "file_checkpoint = \"data/questions/13Marzo2025.json\"\n",
    "\n",
    "# Caricamento domande\n",
    "try:\n",
    "    with open(\"data/questions/6Marzo2025__ALL.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        domande = json.load(f)\n",
    "    print(f\"Caricate {len(domande)} domande\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File domande non trovato.\")\n",
    "    raise\n",
    "\n",
    "# Carica checkpoint\n",
    "def carica_checkpoint():\n",
    "    if os.path.exists(file_checkpoint):\n",
    "        with open(file_checkpoint, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f).get(\"last_index\", 0)\n",
    "    return 0\n",
    "\n",
    "# Salva checkpoint\n",
    "def salva_checkpoint(indice):\n",
    "    with open(file_checkpoint, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"last_index\": indice, \"timestamp\": datetime.now().isoformat()}, f)\n",
    "\n",
    "def test_domande():\n",
    "    assistente = Assistant(\n",
    "        faiss_index=\"data/faiss_index/ALL__11Marzo2025__bge-m3\", \n",
    "        log_file=\"data/logs/TestAssistant13Marzo2025.log\"\n",
    "    )\n",
    "    \n",
    "    indice_inizio = carica_checkpoint()\n",
    "    print(f\"Inizio dal numero {indice_inizio}\")\n",
    "    \n",
    "    for i in tqdm(range(indice_inizio, len(domande))):\n",
    "        domanda = domande[i][\"question\"]\n",
    "        sezione = domande[i][\"section_index\"]\n",
    "        \n",
    "        try:\n",
    "            assistente.clear_history()\n",
    "            inizio = time.time()\n",
    "            risposta = assistente.ask(domanda)[\"final_response\"]\n",
    "            tempo_risposta = time.time() - inizio\n",
    "            \n",
    "            risultato = {\n",
    "                \"question_id\": i + 1,\n",
    "                \"section_index\": sezione,\n",
    "                \"question\": domanda,\n",
    "                \"response\": risposta,\n",
    "                \"response_time\": tempo_risposta,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            with open(f\"{dir_risultati}/question_{i+1}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(risultato, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            salva_checkpoint(i + 1)\n",
    "            time.sleep(random.uniform(3, 8))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Errore domanda {i+1}: {e}\")\n",
    "            errore = {\n",
    "                \"question_id\": i + 1,\n",
    "                \"section_index\": sezione,\n",
    "                \"question\": domanda,\n",
    "                \"error\": str(e),\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            with open(f\"{dir_risultati}/question_{i+1}_error.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(errore, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            salva_checkpoint(i + 1)\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "\n",
    "    print(f\"Test completato! Risultati salvati in {dir_risultati}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_domande()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECUPERO DOMANDE CASUALI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "input_file = \"data/questions/6Marzo2025__ALL.json\"\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "questions = [item[\"question\"] for item in data]\n",
    "num_questions = len(questions)\n",
    "\n",
    "#print('Total Number of questions:', num_questions)\n",
    "\n",
    "#-------------------------------------------------------------------------#\n",
    "NUM_OF_QUESTIONS = 100\n",
    "\n",
    "sample_size = min(NUM_OF_QUESTIONS, num_questions)  \n",
    "sample_questions = random.sample(questions, sample_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST pi√π modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Assistant import Assistant\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "JV_GEMINI_TOKEN = \"AIzaSyArDcTFUTzztpgCIlogXSYQwBhUieZxv7Y\"\n",
    "RS_GEMINI_TOKEN = \"AIzaSyAS0kVBJkyFyosoCwqAQyJM0ElyKEzrmgM\"\n",
    "EZ_GEMINI_TOKEN = \"AIzaSyAVi3tobZhK9uBL-eGyXUcCnRTiEPChsF4\"\n",
    "VM_GEMINI_TOKEN = \"AIzaSyD22Kr3nfSrvkE45KJlbIZHLuTA_cYuBYM\"\n",
    "VM_GEMINI_TOKEN2 = \"AIzaSyAfNu529ZSMYVc2cPrCzaPi5XKlWpi09X0\"\n",
    "JV_COHERE_TOKEN = \"XjJ6nkqZabaMHpq4aehIfyyksudq5LSm80QvUqcV\"\n",
    "RS_COHERE_TOKEN  = \"t1GNKsIULpTSgepiuMsOtGicLqpTgVMX5UNnpiMg\"\n",
    "\n",
    "\n",
    "assistant1 = Assistant(faiss_index=\"data/faiss_index/ALL__22_03_2025__BGE-M3__MAX_INNER_PRODUCT\", \n",
    "                       log_file=\"data/logs/test_2_assistant.log\",\n",
    "                       embedding_model=\"BAAI/bge-m3\",\n",
    "                       generation_model1=\"GEMINI\",\n",
    "                       token1=VM_GEMINI_TOKEN2,\n",
    "                       generation_model2=\"GEMINI\", \n",
    "                       token2=EZ_GEMINI_TOKEN)\n",
    "\n",
    "\n",
    "assistant2 = Assistant(faiss_index=\"data/faiss_index/ALL__22_03_2025__BGE-M3__MAX_INNER_PRODUCT\", \n",
    "                       log_file=\"data/logs/test_2_assistant.log\",\n",
    "                       embedding_model=\"BAAI/bge-m3\",\n",
    "                       generation_model1=\"GEMINI\",\n",
    "                       token1=VM_GEMINI_TOKEN2,\n",
    "                       generation_model2=\"COMMAND_R_PLUS\", \n",
    "                       token2=RS_COHERE_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "skip_first = 0\n",
    "cont = 0\n",
    "\n",
    "responses = {}\n",
    "\n",
    "\n",
    "for q in tqdm(sample_questions, desc=\"Processing questions\"):\n",
    "    cont += 1\n",
    "    if cont <= skip_first:\n",
    "        continue\n",
    "    \n",
    "    responses[q] = {\n",
    "        \"Assistant1\": assistant1.ask(q)['final_response'],\n",
    "        \"Assistant2\": assistant2.ask(q)['final_response']\n",
    "    }\n",
    "    \n",
    "    tempo_casuale_ms = random.randint(5000, 10000) / 1000 \n",
    "    time.sleep(tempo_casuale_ms)\n",
    "\n",
    "output_file = \"data/questions/responses/test_last2Models.json\"\n",
    "\n",
    "import os\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Risposte salvate in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST PIU' MODELLI - Manuale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "JV_GEMINI_TOKEN = \"AIzaSyArDcTFUTzztpgCIlogXSYQwBhUieZxv7Y\"\n",
    "RS_GEMINI_TOKEN = \"AIzaSyAS0kVBJkyFyosoCwqAQyJM0ElyKEzrmgM\"\n",
    "EZ_GEMINI_TOKEN = \"AIzaSyAVi3tobZhK9uBL-eGyXUcCnRTiEPChsF4\"\n",
    "VM_GEMINI_TOKEN = \"AIzaSyD22Kr3nfSrvkE45KJlbIZHLuTA_cYuBYM\"\n",
    "VM_GEMINI_TOKEN2 = \"AIzaSyAfNu529ZSMYVc2cPrCzaPi5XKlWpi09X0\"\n",
    "JV_COHERE_TOKEN = \"XjJ6nkqZabaMHpq4aehIfyyksudq5LSm80QvUqcV\"\n",
    "\n",
    "import importlib\n",
    "import Assistant\n",
    "importlib.reload(Assistant)\n",
    "from Assistant import Assistant\n",
    "\n",
    "\n",
    "assistant = Assistant(faiss_index=\"data/faiss_index/ALL__19_03_2025__BGE-M3__MAX_INNER_PRODUCT\", \n",
    "                       log_file=\"data/logs/assistant.log\",\n",
    "                       generation_model1=\"GEMINI\",\n",
    "                       token1=EZ_GEMINI_TOKEN,\n",
    "                       generation_model2=\"COMMAND_R_PLUS\",\n",
    "                       token2=JV_COHERE_TOKEN)\n",
    "\n",
    "# 100 domande fuori contesto in inglese\n",
    "domande_fuori_contesto_en = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Who won the last Super Bowl?\",\n",
    "    \"How do you cook a Margherita pizza?\",\n",
    "    \"What is the average temperature on Mars?\",\n",
    "    \"Who wrote 'Pride and Prejudice'?\",\n",
    "    \"What is the best exercise to train biceps?\",\n",
    "    \"How much does a ticket to Disneyland cost?\",\n",
    "    \"What is the latest iPhone model released?\",\n",
    "    \"How do you say 'good morning' in Japanese?\",\n",
    "    \"Who directed the movie 'Inception'?\",\n",
    "    \"What is the recipe for tiramisu?\",\n",
    "    \"How do you obtain American citizenship?\",\n",
    "    \"What are the symptoms of seasonal flu?\",\n",
    "    \"Who is the current president of the United States?\",\n",
    "    \"How can I book a flight to Tokyo?\",\n",
    "    \"What is the difference between a dolphin and a whale?\",\n",
    "    \"How can I invest in the stock market?\",\n",
    "    \"What is the most titled football team in the world?\",\n",
    "    \"Who discovered penicillin?\",\n",
    "    \"What is the best science fiction movie of 2024?\",\n",
    "    \"What is the fastest way to lose weight?\",\n",
    "    \"How do you play chess?\",\n",
    "    \"Who invented the steam engine?\",\n",
    "    \"Where is the Grand Canyon located?\",\n",
    "    \"What is the most listened song on Spotify?\",\n",
    "    \"How can I learn to play the guitar?\",\n",
    "    \"Who won the Nobel Prize in Literature in 2023?\",\n",
    "    \"How do you tie a tie?\",\n",
    "    \"What is the difference between a virus and a bacterium?\",\n",
    "    \"What is the best-selling book of all time?\",\n",
    "    \"What is the formula for speed?\",\n",
    "    \"How can I start meditating?\",\n",
    "    \"What are the best restaurants in Rome?\",\n",
    "    \"How do you make homemade bread?\",\n",
    "    \"Who is the founder of Tesla?\",\n",
    "    \"What are the benefits of yoga?\",\n",
    "    \"What is the smartest dog breed?\",\n",
    "    \"How can I improve my memory?\",\n",
    "    \"Where is the Great Wall of China located?\",\n",
    "    \"What is the difference between green tea and black tea?\",\n",
    "    \"How can I quit smoking?\",\n",
    "    \"Who wrote '1984'?\",\n",
    "    \"What is the deepest lake in the world?\",\n",
    "    \"How can I save more money each month?\",\n",
    "    \"What are the signs of the zodiac?\",\n",
    "    \"Who invented the Internet?\",\n",
    "    \"What is the official currency of Japan?\",\n",
    "    \"How can I improve my posture?\",\n",
    "    \"What is the largest planet in the solar system?\",\n",
    "    \"What are the most spoken languages in the world?\",\n",
    "    \"Who discovered America?\",\n",
    "    \"How do you prepare a Mojito cocktail?\",\n",
    "    \"What are the causes of climate change?\",\n",
    "    \"Who is the highest paid soccer player in the world?\",\n",
    "    \"What is the most populous city on Earth?\",\n",
    "    \"How can I improve my productivity?\",\n",
    "    \"Where is the Colosseum located?\",\n",
    "    \"What are the benefits of meditation?\",\n",
    "    \"Who painted the Mona Lisa?\",\n",
    "    \"What is the longest river in the world?\",\n",
    "    \"How can I learn a new language quickly?\",\n",
    "    \"Who wrote 'The Little Prince'?\",\n",
    "    \"What are the symptoms of a panic attack?\",\n",
    "    \"How can I increase my self-esteem?\",\n",
    "    \"What is the best way to relax after a stressful day?\",\n",
    "    \"Who invented the radio?\",\n",
    "    \"What are the best smartphones of 2025?\",\n",
    "    \"How can I improve my diet?\",\n",
    "    \"What is the most active volcano in the world?\",\n",
    "    \"What are the best tourist destinations for 2025?\",\n",
    "    \"Who discovered gravity?\",\n",
    "    \"What is the difference between a psychologist and a psychiatrist?\",\n",
    "    \"How can I make friends more easily?\",\n",
    "    \"What is the most popular color in interior design?\",\n",
    "    \"Where is the Eiffel Tower located?\",\n",
    "    \"How can I protect my online data?\",\n",
    "    \"Who wrote 'The Lord of the Rings'?\",\n",
    "    \"What is the most innovative technology of 2025?\",\n",
    "    \"What are the best action movies of all time?\",\n",
    "    \"How can I improve my posture while working?\",\n",
    "    \"What is the best video game released this year?\",\n",
    "    \"What is the difference between a star and a planet?\",\n",
    "    \"What are the best books to read in 2025?\",\n",
    "    \"How can I better organize my time?\",\n",
    "    \"What is the largest number ever discovered?\",\n",
    "    \"Who won the Oscar for Best Picture in 2024?\",\n",
    "    \"How can I start an online business?\",\n",
    "    \"What are the healthiest foods?\",\n",
    "    \"What is the most visited city in the world?\",\n",
    "    \"Who wrote 'Don Quixote'?\",\n",
    "    \"How can I sleep better at night?\",\n",
    "    \"What is the best advice for success in life?\"\n",
    "]\n",
    "\n",
    "# Esegui il test delle domande fuori contesto\n",
    "risultati = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "skip_first = 0\n",
    "for i, domanda in enumerate(tqdm(domande_fuori_contesto_en, desc=\"Processing questions\")):\n",
    "    if i < skip_first:\n",
    "        continue\n",
    "    cont += 1\n",
    "    response = assistant.ask(domanda)\n",
    "    risultati.append(response)\n",
    "        \n",
    "    tempo_casuale_ms = random.randint(5000, 10000) / 1000 \n",
    "    time.sleep(tempo_casuale_ms)\n",
    "\n",
    "# Salvataggio dei risultati in un file JSON\n",
    "with open(\"test_riformulazione_OUT_OF_CONTEXT2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(risultati, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Test completato. I risultati sono stati salvati.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Salvataggio dei risultati in un file JSON\n",
    "with open(\"test_riformulazione_OUT_OF_CONTEXT2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(risultati, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Test completato. I risultati sono stati salvati.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant.clear_history()\n",
    "\n",
    "# Esegui il test delle domande fuori contesto\n",
    "risultati = []\n",
    "for domanda in tqdm(sample_questions, desc=\"Processing questions\"):\n",
    "    reformulated_query = assistant.query_reformulation_chain.invoke({\n",
    "        \"question\": domanda,\n",
    "        \"chat_history\": assistant.get_history_for_prompt()\n",
    "    })[\"text\"].strip()\n",
    "    risultati.append({\"domanda\": domanda, \"query_riformulata\": reformulated_query})    \n",
    "   \n",
    "    tempo_casuale_ms = random.randint(5000, 10000) / 1000 \n",
    "    time.sleep(tempo_casuale_ms)\n",
    "\n",
    "\n",
    "# Salvataggio dei risultati in un file JSON\n",
    "with open(\"test_riformulazione_en.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(risultati, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Test completato. I risultati sono stati salvati in 'test_riformulazione_IN_CONTEXT.json'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
