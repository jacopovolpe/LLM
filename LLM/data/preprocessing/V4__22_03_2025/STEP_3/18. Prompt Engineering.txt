## Lesson 18 ##

key concepts of Prompt Engineering, a crucial area within Natural Language Processing (NLP) and Large Language Models (LLMs). This material is from Lesson 18 of a Corso di Laurea Magistrale in Ingegneria Informatica (Master's Degree Course in Computer Engineering), instructed by Nicola Capuano and Antonio Greco at DIEM – University of Salerno.

### Outline

The content is structured into three main sections:

*   Introduction to Prompt Engineering
*   Prompt Engineering Techniques
*   Prompt Testing

`<----------section---------->`

### Introduction to Prompt Engineering

**Prompt Engineering:** This is a relatively new discipline that focuses on the design and optimization of prompts used to interact with LLMs. The aim is to effectively leverage LLMs for a wide array of applications and research endeavors. Effective prompt engineering is essential because LLMs respond differently based on the input prompts they receive. Optimizing these prompts can significantly improve the quality and relevance of the output.

**Goals:**

*   **Enhances understanding of LLM capabilities and limitations:** By experimenting with different prompts, engineers gain insights into what LLMs can and cannot do. This understanding is crucial for setting realistic expectations and identifying appropriate use cases.
*   **Improves LLM performance on a broad range of tasks:** Optimized prompts can enhance the accuracy, coherence, and relevance of LLM outputs across various tasks, including question answering and arithmetic reasoning.
*   **Helps interfacing with LLMs and integrating with other tools:** Prompt engineering facilitates the integration of LLMs into broader workflows and systems, allowing them to interact seamlessly with other software and data sources.
*   **Enables new capabilities:** Well-crafted prompts can unlock new functionalities in LLMs, such as augmenting them with domain-specific knowledge and external resources, thereby extending their applicability.

`<----------section---------->`

### Writing Good Prompts

Effective prompt writing is an iterative process involving experimentation and refinement:

*   **Start Simple and Iterate:** Begin with basic prompts and gradually add elements, refining through iteration to achieve desired results. This incremental approach allows for better control and understanding of how each element affects the outcome.
*   **Use Clear, Specific Instructions:** Employ explicit directives such as “Write,” “Classify,” or “Summarize” at the beginning of prompts to guide the LLM's actions. Clear instructions reduce ambiguity and help the model focus on the intended task.
*   **Be Detailed and Descriptive:** Provide ample detail to guide the model toward better outcomes. The more context and specifics included, the more accurate and relevant the responses are likely to be.
*   **Consider Examples:** Incorporate examples to illustrate the desired output format and content. Examples provide the model with concrete patterns to follow, improving the consistency and quality of its responses.
*   **Balance Detail and Length:** Carefully manage the level of detail and length of prompts. Excessive information can dilute effectiveness, while insufficient detail may lead to suboptimal results. Experimentation is key to finding the ideal balance.

`<----------section---------->`

### Writing Good Prompts - Examples

This section illustrates the difference between poorly written and well-crafted prompts:

*   **Text Summarization**
    *   **Bad Prompt:** “Summarize this article.” (Too vague, lacks specifics)
    *   **Good Prompt:** “Generate a 100-word summary of this research article, focusing on the main findings.” (Specific word count, clear focus)
*   **Email Composition**
    *   **Bad Prompt:** “Write an apology email to a client.” (Lacks context and detail)
    *   **Good Prompt:** “Write a professional email to a client apologizing for a delayed shipment, offering a discount, and providing an updated delivery estimate.” (Includes specific actions and reasons)
*   **Simplification of Explanation**
    *   **Bad Prompt:** “Make this explanation easier to understand.” (Unclear target audience)
    *   **Good Prompt:** “Rewrite this technical explanation in simpler language suitable for high school students.” (Defines target audience, sets comprehension level)
*   **Review Classification**
    *   **Bad Prompt:** “Classify the following review.” (Missing classification categories)
    *   **Good Prompt:** “Classify the following review as positive, neutral, or negative.” (Provides explicit classification options)
*   **Information Provision**
    *   **Bad Prompt:** “Tell me about exercise benefits.” (Too broad, lacks focus)
    *   **Good Prompt:** “List five health benefits of regular exercise, each with a short explanation of how it improves well-being.” (Specifies number of benefits, requires explanation)
*   **Translation**
    *   **Bad Prompt:** “Translate this sentence to French.” (Lacks tone specification)
    *   **Good Prompt:** “Translate the following English sentence into French, preserving the formal tone.” (Requests specific tone)

`<----------section---------->`

### Elements of a Prompt

A well-structured prompt typically includes these components:

*   **Instruction:** The specific task or action requested from the model (e.g., classify, summarize, translate).
*   **Context:** Background information or additional details that guide the model toward better responses. Providing context helps the model understand the nuances of the request.
*   **Input Data:** The data or question for which a response is needed. This is the primary content the model will process.
*   **Output Indicator:** The desired type or format of the output (e.g., a summary, a classification, a code snippet). This helps the model structure its response appropriately.

**Example 1:**

```
Classify the text into neutral, negative or positive.
Text: I think the vacation is okay.
Sentiment: [Output Indicator]
```

In this example:

*   Instruction: Classify the text...
*   Input: I think the vacation is okay
*   Output Indicator: Sentiment

**Example 2:**

```
Answer the question based on the context below. Keep the answer short and concise. Respond "Unsure about answer" if not sure about the answer.

Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.

Question: What was OKT3 originally sourced from?
Answer: [Output Indicator]
```

In this example:

*   Instruction: Answer the question...
*   Context: Teplizumab traces its roots...
*   Input: What was OKT3 originally sourced from?
*   Output Indicator: Answer

`<----------section---------->`

### In-Context Learning

In-context learning is the ability of an LLM to perform tasks by leveraging information provided within the prompt (context) without altering its internal parameters. It enables LLMs to adapt to new tasks and datasets with minimal training.

Elements of a prompt context include:

*   **Reference Material:** Specific texts or data used to perform the task.
*   **Input-Output Pairs:** Examples of the task to illustrate the desired pattern, guiding the model with concrete instances.
*   **Step-by-Step Instructions:** Detailed guidance for completing the task, providing a clear process for the model to follow.
*   **Clarifications:** Addressing potential ambiguities in the task to minimize misinterpretations.
*   **Templates:** Structures or placeholders to be filled in, providing a framework for the model to generate structured outputs.

Prompt engineering heavily relies on in-context learning to maximize the effectiveness of LLMs.

`<----------section---------->`

### Prompts and NLP Tasks

Prompts can be tailored to achieve various NLP tasks:

*   **Text Summarization:**
    ```
    Antibiotics are a type of medication used to treat bacterial infections. They work by either killing
    the bacteria or preventing them from reproducing, allowing the body’s immune system to fight off the
    infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions,
    or sometimes administered intravenously. They are not effective against viral infections, and using
    them inappropriately can lead to antibiotic resistance.

    Explain the above in one sentence:
    ```
    **Output:**
    ```
    Antibiotics are medications used to treat bacterial infections by either killing the bacteria or
    stopping them from reproducing, but they are not effective against viruses and overuse can lead to
    antibiotic resistance.
    ```
*   **Information Extraction:**
    ```
    Author-contribution statements and acknowledgements in research papers should state clearly and
    specifically whether, and to what extent, the authors used AI technologies such as ChatGPT in the
    preparation of their manuscript and analysis. They should also indicate which LLMs were used. This
    will alert editors and reviewers to scrutinize manuscripts more carefully for potential biases,
    inaccuracies and improper source crediting. Likewise, scientific journals should be transparent about
    their use of LLMs, for example when selecting submitted manuscripts.

    Mention the large language model based product mentioned in the paragraph above:
    ```
    **Output:**
    ```
    The large language model based product mentioned in the paragraph above is ChatGPT.
    ```
*   **Question Answering:**
    ```
    Answer the question based on the context below. Keep the answer short and concise. Respond "Unsure
    about answer" if not sure about the answer.

    Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There,
    scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the
    molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986,
    it was approved to help prevent organ rejection after kidney transplants, making it the first
    therapeutic antibody allowed for human use.

    Question: What was OKT3 originally sourced from?
    ```
    **Output:**
    ```
    Mice
    ```
*   **Text Classification:**
    ```
    Classify the text into neutral, negative or positive.
    Text: I think the food was okay.
    Sentiment:
    ```
    **Output:**
    ```
    Neutral
    ```
*   **Code Generation:**
    ```
    Write a JavaScript code that prompts the user to enter their name and then displays
    a “Hello” message.
    Output only the code, no additional comments.
    ```
    **Output:**
    ```javascript
    let name = prompt("What is your name?");
    console.log(`Hello, ${name}!`);
    ```
*   **Reasoning:**
    ```
    What is 9,000 * 9,000?
    ```
    **Output:**
    ```
    81,000,000
    ```
    Note: despite advancements in mathematical capabilities, reasoning tasks remain challenging for LLMs...
*   **Reasoning (Example of Failure):**
    ```
    The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.
    Answer:
    ```
    **Output:**
    ```
    No, the odd numbers in this group add up to an odd number: 119.
    ```
    That's incorrect! More advanced prompt engineering techniques are needed to obtain the correct answer... we will discuss them later.

`<----------section---------->`

### System Prompts

A system prompt is a configuration provided to the AI model before any user interaction. It serves as a foundational setup that guides the model's behavior.

*   **Purpose:** Establishes the assistant's behavior, context, tone, and any specific instructions or constraints.
*   **Function:** Guides the model on how to respond and what it should focus on, setting the stage for subsequent interactions.

**Examples:**

*   "You are a helpful and knowledgeable assistant who answers questions accurately and concisely." (Defines role and response style)
*   "You are an IT support assistant specializing in troubleshooting software and hardware issues. Respond politely and guide users through step-by-step solutions." (Specifies expertise and interaction approach)
*   "You are a friendly and engaging AI who responds in a warm and conversational tone, keeping responses lighthearted and approachable." (Sets tone and communication style)

`<----------section---------->`

### Prompt Engineering Techniques
you can use several prompt techniques to improve de capabilities of a llm's without changes the weights of the model.
    - Zero-shot Prompting
    - Few-shot prompting
    - chain of though prompting
    - self-consinstency prompting
    - meta prompting
    - task-agnostic meta prompting
    - meta-meta prompting
    - prompt chaining
    - role prompting
    - stuctured prompting
    - generate knowledge prompting
    
<----------section---------->
### Prompt Engineering Techniques

*   **Zero-Shot Prompting:**
    *   Definition: A prompt that directly instructs the model without including any examples or demonstrations.
    *   Principle: Leverages the LLM's pre-existing knowledge and capabilities gained from large-scale training to perform tasks without explicit examples.
    *   **Example:**
        ```
        Classify the text into neutral, negative or positive.
        Text: I think the vacation is okay.
        Sentiment:
        ```

        **Output:**
        ```
        Neutral
        ```
        The LLM already understands the concept of “sentiment” (that's the zero-shot capabilities at work).

<----------section---------->
### Prompt Engineering Techniques

*   **Few-Shot Prompting:**
    *   Definition: Involves including examples or demonstrations within the prompt to guide the model towards better performance.
    *   Principle: Leverages in-context learning, where the LLM learns from the provided examples to generate more accurate responses.
    *   **Example:**
        ```
        A "whatpu" is a small, furry animal native to Tanzania. An example of a sentence that uses the word whatpu is: We were traveling in Africa, and we saw these very cute whatpus.
        To do a "farduddle" means to jump up and down really fast. An example of a sentence that uses the word farduddle is: When we won the game, we all started to farduddle in celebration.
        ```

    *   **Limitations:** Effective for many tasks but may struggle with complex reasoning.

    *   **Zero-Shot Example:**
        ```
        The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.
        Answer:
        ```

        **Output:**
        ```
        Yes, the odd numbers in this group add up to 107, which is an even number.
        ```
        False! Let's try with few-shot prompting.

    *   **Few-Shot Example:**
        ```
        The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.
        A: The answer is False.
        The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.
        A: The answer is True.
        The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.
        A: The answer is True.
        The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.
        A: The answer is False.
        The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.
        A:
        ```

        **Output:**
        ```
        The answer is True.
        ```
        False Again!

<----------section---------->
### Prompt Engineering Techniques

*   **Chain-of-Thought Prompting:**
    *   Definition: Enhances complex reasoning by guiding the model through intermediate reasoning steps.
    *   Principle: Breaks down a complex problem into a series of smaller, more manageable steps, allowing the LLM to follow a logical chain of reasoning.

    | Standard Prompting                                                                                                                                              | Chain-of-Thought Prompting                                                                                                                                                  |
    | :-------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?A: The answer is 11. | Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?A: 2 cans of tennis balls is 2*3=6 tennis balls.  Then he has 5+6=11 tennis balls. The answer is 11. |
    | Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?A: The answer is 27.                           | Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?A: They had 23 apples, used 20, that means 23-20 = 3 apples remaining.  Then bought 6 more, so there are 3+6=9 apples. The answer is 9. |

    *Combining it with few-shot prompting can yield better results on even more complex tasks.*

    *   **Example:**
        ```
        The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.
        A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.
        The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.
        A: Adding all the odd numbers (17, 19) gives 36. The answer is True.
        The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.
        A: Adding all the odd numbers (11, 13) gives 24. The answer is True.
        The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.
        A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.
        The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.
        A:
        ```

        **Output:**
        ```
        Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False.
        ```
        Correct! Note: this is an emergent ability that arises with sufficiently large language models.

<----------section---------->
### Prompt Engineering Techniques

*   **Self-Consistency Prompting:**
    *   Definition: Employs an iterative chain-of-thought approach.
    *   Principle: Repeats the question multiple times to generate a range of reasoning paths, selecting the most frequent answer as the final response.

<----------section---------->
### Prompt Engineering Techniques

*   **Meta Prompting:**
    *   Definition: Guides the model through the logical steps required to solve a problem without relying on specific content-based examples.
    *   Principle: Focuses on the process rather than the content, allowing the LLM to apply a structured approach to problem-solving.
    *   **Example:**
        ```
        Solve the quadratic equation 3x² + 4x - 5 = 0 by following these structured steps:
        1. Identify and Set Up the Formula: Recognize that this is a quadratic equation in the form ax² + bx + c = 0.
        2. Apply the Quadratic Formula: Use the quadratic formula x = (-b ± √(b² - 4ac)) / (2a) and substitute in the values.
        3. Calculate the Discriminant: Find b² - 4ac, and interpret its value to determine the nature of the roots.
        4. Solve for x: Perform the calculation for both + and - options in the formula to find the values of x.
        5. Verify the Solution: Substitute each value of x back into the original equation to confirm it satisfies it.
        6. Summarize the Results: State the final solution, listing both values of x and noting any observations about the nature of the roots.
        ```
<----------section---------->
### Prompt Engineering Techniques

*   **Task-Agnostic Meta Prompting:**
    *   Definition: Achieves good results by simply asking the model to reason step-by-step, without specifying the content of each step.
    *   Principle: Relies on the LLM's general reasoning abilities to structure its response in a logical and coherent manner.
    *   **Example:**
        ```
        Problem Statement:
        * Problem: [question to be answered]
        Solution Structure:
        * Begin the response with "Let’s think step by step."
        * Follow with the reasoning steps, ensuring the solution process is broken down clearly and logically.
        * End the solution with the final answer encapsulated in a LaTeX-formatted box, 4, for clarity and emphasis.
        * Finally, state "The answer is [final answer to the problem].", with the final answer presented in LaTeX notation.
        ```
<----------section---------->
### Prompt Engineering Techniques

*   **Meta Meta Prompting:**
    *   Definition: Utilizes LLMs to generate prompts that guide further tasks.
    *   Principle: Automates the creation of effective prompts, allowing for more efficient and scalable prompt engineering.
    *   **Example:**
        *   **Prompt:**
            ```
            Create a detailed metaprompt to guide an AI in solving a differential equation. Your metaprompt
            should focus on ensuring that the AI identifies the type of differential equation, selects the
            appropriate method for solving it, and presents a clear, step-by-step solution. Include instructions

            for verifying the solution and summarizing the results.
            ```
        *   **Output:**
            ```
            To solve this differential equation, follow these steps carefully:
            1. Identify the Type: Begin by identifying the type of differential equation (e.g., first-order linear,
            separable, homogeneous, etc.). Briefly explain how you recognized the type.

            2. Apply an Appropriate Method: Based on the type, outline the most suitable method for
            solving it (e.g., separation of variables, integrating factor, etc.). If there are multiple
            approaches, describe why this particular method is the best choice.

            3. Show Step-by-Step Solution: Work through the equation step-by-step, explaining each
            manipulation and transformation in clear terms.

            4. Verify Solution: Once you find the solution, verify it by differentiating the result and
            substituting it back into the original equation to confirm it satisfies the differential equation.

            5. Summarize the Solution: Finally, summarize the general or particular solution, highlighting

            any constants or special conditions that apply.
            ```
<----------section---------->
### Prompt Engineering Techniques

*   **Prompt Chaining:**
    *   Definition: Breaks down a complex task into different parts, each handled by a specific prompt.
    *   Principle: Manages intricate queries by dividing them into manageable segments, using the output of one prompt as the input for the next.
    *   **Example:**
        ```
        Extract any relevant quotes from the following text to answer the question "What was the main cause of the American Civil War?" [reference text follows]

        "One of the biggest catalysts of the Civil War was the issue of slavery, particularly the Southerners’ desire to bring slavery into the territories."
        "Tensions peaked when the Republican candidate Abraham Lincoln was elected president in 1860 with a platform opposing the extension of slavery into the territories, which isolated the South."

        Using the extracted quotes and the full text, provide a detailed answer to the question "What was the main cause of the American Civil War?"
        ```

        **Output:**
        ```
        The main cause of the American Civil War was the issue of slavery and its potential expansion into new territories and states. The South insisted on bringing slavery into new territories, while the election of Abraham Lincoln with an anti-slavery platform isolated the Southern states, which feared losing the right to own slaves. The fundamental disagreement over slavery between the North and South was the key factor that ultimately led to the outbreak of the Civil War.
        ```
<----------section---------->
### Prompt Engineering Techniques

*   **Role Prompting:**
    *   Definition: Asks the model to assume a specific role or persona.
    *   Principle: Adjusts the tone, style, and depth of information provided based on the assigned role.
    *   **Examples:**
        *   Write a review of [pizza place]
        *   You are a food critic writing for the Michelin Guide. Write a review of [pizza place]
        *   You are a marketing expert. Draft an email to a client advising them about a delay in the delivery schedule due to logistical problems.
        *   You are a customer service representative. Draft an email to a client advising them about a delay in the delivery schedule due to logistical problems.

    *   **Example of Role Prompting effect:**
        *   Without RP: Write a review of [pizza place]
        *   With RP: You are a food critic writing for the Michelin Guide. Write a review of [pizza place]

    *   **Example of Role Prompting effect (Marketing Expert):**
        *   You are a marketing expert. Draft an email to a client advising them about a delay in the delivery schedule due to logistical problems. (focus on persuasion, positivity, and relationship)

          ```
          Subject: A Little More Wait for Your Wonderful Products

          Dear [Client's Name],

          We hope this message finds you buzzing with excitement for your upcoming
          order! However, even the best-laid plans sometimes face unexpected
          hiccups. We have hit a temporary logistics snag that will unfortunately
          add a small wait time to your delivery.

          While we understand this isn't ideal, we believe great things come to
          those who wait, and your order is no exception. Rest assured, from the
          moment we sort out this situation to the time your products reach you,
          we're committed to ensuring that your experience is nothing short of
          excellent.

          Thank you for your patience and understanding. Stay tuned for more
          updates, and please, don't hesitate to reach out if you have any questions
          — we're always here.

          Cheers, [Your Name]
          ```

    *   **Example of Role Prompting effect (Customer Service):**
        *   You are a customer service representative. Draft an email to a client advising them about a delay in the delivery schedule due to logistical problems. (More relational and solution-oriented)

          ```
          Subject: Attention Required: Update on Your Order Status

          Dear [Client's Name],

          Greetings from [Your Company Name].

          We wanted to inform you that, due to unforeseen logistical challenges,
          there might be a delay in the delivery of your order. We understand that
          this may cause some inconvenience, and we apologize sincerely.
          Meanwhile, we are working tirelessly to resolve this and ensure your
          delivery reaches you by [new estimated date]. We value your time and
          patience greatly.

          Please feel free to reach out if you have any questions or need further
          information. Our team is always here to assist you.

          Thank you for your understanding.

          Best regards, [Your Name]
          ```
<----------section---------->
### Prompt Engineering Techniques

*   **Structured Prompting:**
    *   Definition: Employs a semi-formal definition of instructions to help LLMs handle complex tasks more predictably.
    *   Principle: Divides the prompt into sections and encodes it into a script, using delimiters to help LLMs recognize each part as distinct units of meaning.
    *   Delimiters: Any unique character sequence that wouldn't normally appear together (e.g., `###`, `===`, `>>>`) or XML tags.
    *   Rationale: LLMs are often trained on web content and have learned to recognize and understand this formatting.

    *   **Example with custom delimiters:**
        ```
        Classify the sentiment of each conversation in <<<CONVERSATIONS>>> as ‘Positive’ or ‘Negative’. Give the sentiment classifications without any other preamble text.

        ###EXAMPLE CONVERSATIONS
        [Agent]: Good morning, how can I assist you today?
        [Customer]: This product is terrible, nothing like what was advertised!
        [Customer]: I’m extremely disappointed and expect a full refund.

        [Agent]: Good morning, how can I help you today?
        [Customer]: Hi, I just wanted to say that I’m really impressed with your product. It exceeded my expectations!
        ###

        ###EXAMPLE OUTPUTS
        Negative
        Positive
        ###

        <<<CONVERSATIONS>>>
        [Agent]: Hello! Welcome to our support. How can I help you today?
        [Customer]: Hi there! I just wanted to let you know I received my order, and it’s fantastic!
        [Agent]: That’s great to hear! We’re thrilled you’re happy with your purchase. Is there anything else I can assist you with?
        [Customer]: No, that’s it. Just wanted to give some positive feedback. Thanks for your excellent service!

        [Agent]: Hello, thank you for reaching out. How can I assist you today?
        [Customer]: I’m very disappointed with my recent purchase. It’s not what I expected at all.
        [Agent]: I’m sorry to hear that. Could you please provide more details so I can help?
        [Customer]: The product is of poor quality, and it arrived late. I’m really unhappy with this experience.
        >>>
        ```

        **Output:**
        ```
        Positive
        Negative
        ```

    *   **Example with XML tags:**
        ```xml
        <prompt>
            <instruction>Classify the sentiment of the following conversations into one of two classes, using the examples given. Give the sentiment classifications without any other preamble text.</instruction>
            <classes>
                <positive>Positive</positive>
                <negative>Negative</negative>
            </classes>
            <example-conversations>
                <conversation>
                    [Agent]: Good morning, how can I assist you today?
                    [Customer]: This product is terrible, nothing like what was advertised!
                    [Customer]: I’m extremely disappointed and expect a full refund.
                </conversation>
                <conversation>
                    [Agent]: Good morning, how can I help you today?
                    [Customer]: Hi, I just wanted to say that I’m really impressed with your product. It exceeded my expectations!
                </conversation>
            </example-conversations>
            <example-classes>
                <class>Negative</class>
                <class>Positive</class>
            </example-classes>
            <conversations>
                <conversation>
                    [Agent]: Hello! Welcome to our support. How can I help you today?
                    [Customer]: Hi there! I just wanted to let you know I received my order, and it’s fantastic!
                    [Agent]: That’s great to hear! We’re thrilled you’re happy with your purchase. Is there anything else I can assist you with?
                    [Customer]: No, that’s it. Just wanted to give some positive feedback. Thanks for your excellent service!
                </conversation>
                <conversation>
                    [Agent]: Hello, thank you for reaching out. How can I assist you today?
                    [Customer]: I’m very disappointed with my recent purchase. It’s not what I expected at all.
                    [Agent]: I’m sorry to hear that. Could you please provide more details so I can help?
                    [Customer]: The product is of poor quality, and it arrived late. I’m really unhappy with this experience.
                </conversation>
            </conversations>
        </prompt>
        ```

        **Output:**
        ```
        Positive
        Negative
        ```

*   **Structured Prompting with CO-STAR:**
    *   Definition: The CO-STAR framework divides a prompt into specific sections to improve clarity and guide the LLM.
    *   Principle: By structuring the prompt into Context, Objective, Style, Tone, Audience, and Response, the LLM can better understand the task and generate more appropriate and effective outputs.
    *   Components:
        *   **Context:** Background information on the task.
        *   **Objective:** Clear definition of the task.
        *   **Style:** Desired writing style.
        *   **Tone:** Desired emotional context (e.g., formal, humorous, empathetic).
        *   **Audience:** Intended recipients (experts, beginners, etc.).
        *   **Response:** Defines the desired output format (text, list, table, JSON).

<----------section---------->
### Prompt Engineering Techniques

*   **Generate Knowledge Prompting:**
    *   Definition: First prompts the LLM to generate relevant knowledge related to a task, then incorporates that knowledge into the prompt along with the task description or question.
    *   Principle: Leverages the LLM's capacity to generate supplementary knowledge beyond its base training domain. Useful when the LLM lacks the specific information required to directly answer a query.
    *   **Example:**
        ```
        List and describe the key factors that influence the evolution of life in
        environments with extreme gravitational forces, such as on a super-Earth
        planet. Focus on biological, physiological, and ecological adaptations
        that might arise in such conditions.

        Using the adaptations and factors you described earlier, design a
        hypothetical intelligent species that could evolve on a super-Earth planet
        with extreme gravitational forces. Include details about their physical
        structure, social behaviors, methods of tool use or communication, and how
        their adaptations influence their culture or technology.
        ```

<----------section---------->

*   **Retrieval Augmented Generation (RAG):**
    *   Definition: Combines retrieval techniques with text generation.
    *   Principle: Addresses limitations in LLMs accessing updated or domain-specific data by using a search or retrieval system to find relevant documents or data, then using an LLM to generate responses conditioned on the retrieved data.
    *   Components:
        *   Retrieval System: Uses search engines or databases to find relevant documents.
        *   LLM: Generates responses based on the retrieved data.

`<----------section---------->`

**Prompt Engineering Guide:** [https://www.promptingguide.ai/](https://www.promptingguide.ai/)

*   Tree of Thoughts
*   Automatic Reasoning and Tool-use
*   Automatic Prompt Engineer
*   Active-Prompt
*   Directional Stimulus Prompting
*   Program-Aided Language Models

**Text-Base Prompt Tech. (List from figure 2.2)**

|                     |                      |                      |                      |                      |
| :------------------ | :------------------- | :------------------- | :------------------- | :------------------- |
| **Zero-Shot**       | **Few-Shot**         | **Thought Generation** | **Decomposition**    | **Ensembling**       |
| Emotion Prompting   | Exemplar Generation  | Chain-of-Thought(CoT) | DECOMP               | COSP                 |
| Role Prompting      | Exemplar Ordering    | Zero-Shot CoT        | Faithful CoT         | DENSE                |
| Style Prompting     | Exemplar Selection   | Analogical Prompting | Least-to-Most        | DiVeRSe              |
| S2A                 | KNN                  | Step-Back Prompting  | Plan-and-Solve       | Max MutualInformation |
| SimToM              | Vote-K               | Thread-of-Thought(ThoT) | Program-of-Thought | Meta-CoT             |
| RaR                 | Prompt Mining        | Tab-CoT              | Recurs.-of-Thought | MoRE                 |
| RE                  | SG-ICL               | Few-Shot CoT         | Skeleton-of-Thought | Self-Consistency     |
| Self-Ask            |                      | Active-Prompt        | Tree-of-Thought      | USP                  |
|                     |                      | Auto-CoT             |                      | Prompt Paraphrasing  |
|                     |                      | Complexity-Based     |                      | Self-Criticism       |
|                     |                      | Contrastive          |                      | Chain-of-Veriﬁcation|
|                     |                      | Memory-of-Thought    |                      | Self-Calibration     |
|                     |                      | Uncertainty-RoutedCoT|                      | Self-Reﬁne          |
|                     |                      |                      |                      | Self-Veriﬁcation      |
|                     |                      |                      |                      | ReverseCoT           |
|                     |                      |                      |                      | Cumulative Reason    |

**The Prompt Report: A Systematic Survey of Prompting Techniques**: [https://arxiv.org/abs/2406.06608](https://arxiv.org/abs/2406.06608)

`<----------section---------->`

### Prompt Testing

**Prompt Testing:** Essential for achieving optimal responses across various use cases. It involves experimenting with various prompts to identify the most effective structures and formats.

**Prompt Testing Tools:**

*   Simplify the creation and testing of prompts.
*   Enable iterative adjustments to discover the best structure and format.
*   Support customizable model settings to control output style, tone, and precision.

**Some available tools:**

*   OpenAI Playground: Supports GPT models ([https://platform.openai.com/playground/](https://platform.openai.com/playground/))
*   Google AI Studio: Supports Google Gemini models ([https://aistudio.google.com](https://aistudio.google.com))
*   LM Studio: Supports Hugging Face models ([https://lmstudio.ai/](https://lmstudio.ai/))

`<----------section---------->`


### LLM Settings

When designing prompts, you interact with the LLM via an API, where you can adjust several key parameters:

*   **Temperature:** Controls randomness. Lower values (e.g., 0.2) make responses more deterministic, suitable for factual tasks. Higher values (e.g., 0.8) encourage creativity, ideal for tasks like poem generation.
*   **Top P:** Adjusts response diversity by limiting token choices to a probability threshold. Lower values ensure precision, while higher values encourage more varied outputs.
    *   Example: if Top P = 0.5, the model considers only the most probable tokens until their summed probability adds up to 50%.
*   **Max Length:** Sets the token limit for responses, helping to control response length and cost.
*   **Stop Sequences:** Define a stopping point for responses, which can prevent overly long outputs and help structure responses, such as ending when a particular token is generated.
*   **Frequency Penalty:** Reduces repetition by penalizing words based on their frequency in the response, useful for avoiding redundant language.
*   **Presence Penalty:** Applies a consistent penalty to repeated tokens, regardless of how many times they appear. Higher values encourage more varied language.
*   **Response Format:** Expected format of the response (text, Json, …)

`<----------section---------->`

### LM Studio

LM Studio: A Desktop Application for Local LLM Development and Experimentation.

**Key functionality:**

*   Search & Download Models directly from Hugging Face
*   Run LLMs on your computer
*   Interactive Chat Interface to test and interact with LLMs
*   Local API Server enabling LLM integration with external applications
*   Model Management Tools to organize and configure local models

Additional info on https://lmstudio.ai/
