**Original Text:**
Natural Language Processing and Large Language Models. Corso di Laurea Magistrale in Ingegneria Informatica. Lesson 8: Building a Chatbot. Nicola Capuano and Antonio Greco, DIEM – University of Salerno.

**Exercise: Building a Pizzeria Chatbot**

Develop a chatbot to assist with pizzeria operations. Users can:

*   Request the pizzeria's menu.
*   Order a pizza that is available on the menu (just one pizza, no beverage).
*   Upon order confirmation, the bot will log the date, the user ID, and the kind of ordered pizza (use a custom action).
*   The bot has a web-based GUI.

Hint: Start with a dummy bot.

Example conversation:

User: Can I have the menu?
Bot: What kind of pizza would you like? We have Parenti, Pepperoni, Vegetarian...
User: Pepperoni
Bot: You want a Pepperoni pizza. Is that correct?
User: Yes
Bot: Great! Your Pepperoni pizza is on its way!

**Hints**

Start with a dummy bot:

```bash
mkdir pizzaBot
cd pizzaBot
rasa init --no-prompt
```

Configure and run the REST and the Actions servers:

```bash
rasa run --cors "*"
rasa run actions
```

Use a Web frontend like:

[https://github.com/JiteshGaikwad/Chatbot-Widget/tree/Widget2.0](https://github.com/JiteshGaikwad/Chatbot-Widget/tree/Widget2.0)

**Enhanced Text:**
This material comes from a lesson on Natural Language Processing (NLP) and Large Language Models (LLMs), part of the "Corso di Laurea Magistrale in Ingegneria Informatica" (Master's Degree Course in Computer Engineering). This specific lesson, Lesson 8, focuses on building a chatbot. The lesson is presented by Nicola Capuano and Antonio Greco from DIEM (Department of Information Engineering and Mathematics) at the University of Salerno.

The core task presented is an:

**Exercise: Building a Pizzeria Chatbot**

The goal is to create a chatbot capable of assisting with basic pizzeria operations. The intended functionalities include:

*   **Menu Request:**  The chatbot should be able to provide the pizzeria's menu to the user upon request.
*   **Pizza Ordering:**  Users should be able to order a single pizza from the available menu options. Note that the bot is restricted to pizza orders only, without beverages.
*   **Order Logging:** Upon successful order confirmation, the chatbot needs to log specific details, including:
    *   Date of the order
    *   User ID (to identify the customer)
    *   Type of pizza ordered (e.g., Pepperoni, Vegetarian)

    This functionality requires the implementation of a custom action within the chatbot framework.  Custom actions allow developers to extend the bot's capabilities beyond simple pre-defined responses. They can involve database interactions, API calls, or, in this case, logging order details.
*   **Web-Based GUI:** The chatbot must have a web-based Graphical User Interface (GUI), making it accessible through a web browser.

A helpful suggestion for approaching this task is to:

*   **Hint: Start with a dummy bot:** Begin with a basic, non-functional chatbot to establish the fundamental structure and workflow before adding complex features.

To illustrate the interaction, an example conversation is provided:

User: Can I have the menu?
Bot: What kind of pizza would you like? We have Parenti, Pepperoni, Vegetarian...
User: Pepperoni
Bot: You want a Pepperoni pizza. Is that correct?
User: Yes
Bot: Great! Your Pepperoni pizza is on its way!

This example shows the bot's expected behavior in handling a menu request, taking a pizza order, and providing confirmation.

To aid in the development process, several hints and setup instructions are given:

*   **Dummy Bot Setup:**

    ```bash
    mkdir pizzaBot
    cd pizzaBot
    rasa init --no-prompt
    ```

    These commands will create a new directory named "pizzaBot," navigate into it, and initialize a new Rasa project without prompting for any user input.  Rasa is an open-source conversational AI framework used for building chatbots. The `--no-prompt` option bypasses interactive configuration, using default settings.
*   **Server Configuration:**

    ```bash
    rasa run --cors "*"
    rasa run actions
    ```

    These commands are crucial for running the chatbot.  `rasa run --cors "*"` starts the Rasa server, which handles the chatbot's core logic and communication with the user interface. The `--cors "*"` flag enables Cross-Origin Resource Sharing, allowing the web-based GUI to communicate with the Rasa server, regardless of the domain serving the GUI. `rasa run actions` starts the Actions server, which is responsible for executing custom actions, such as logging the order details to a database.
*   **Web Frontend Resource:**

    [https://github.com/JiteshGaikwad/Chatbot-Widget/tree/Widget2.0](https://github.com/JiteshGaikwad/Chatbot-Widget/tree/Widget2.0)

    This link points to a GitHub repository containing a suitable web frontend widget that can be used to create the web-based GUI for the chatbot.  The specific branch "Widget2.0" is referenced.

<----------section---------->
**Additional Context:**
fly. When you need to inspire students and keep them engaged. Teachers do
this naturally, by adjusting what they say and how they say it based on
feedback on how well the student understand what they are saying. And
teachers think about more than just "delivering a message." They must think
up new ideas and approaches, on the fly as students pose interesting new
questions. Inspiring students' curiosity with Socratic questions and being
responsive to their changing needs is a full-time job.
It is virtually impossible to build a rule-based system that captures all the
things that teachers do to help students learn and grow. Students' needs are
too diverse and dynamic. This is why hybrid chatbots that integrate LLMs
have become the preferred way build production chatbots in virtually every
domain. An LLM can confidently and convincingly chat with your users on
virtually any topic. The key is to harness this power smartly, so that it doesn’t
mislead your users, or worse.
12.5 Chatbot frameworks
In each of the previous chapters, you’ve learned a new technique for
processing text to understand what the user is saying. And in this chapter,
you’ve learned four approaches to generating text for a chatbot to use in its
response to the user. You’ve already assembled a few chatbots from these
NLU and NLG algorithms to understand the advantages and disadvantages of
each of these algorithms. Now you have the knowledge you need to use a
chatbot framework
 smartly. A chatbot framework is an application and a
software library that abstracts away some of these detailed decisions you
need to make when building a dialog engine for your chatbot. A framework
gives you a way to specify your chatbot’s behavior in 
domain-specific
language
 that it can later interpret and 
run
 so that your chatbot replies the
way you intended.
Most chatbot frameworks use a declarative programming language to specify
a bot’s behavior and some even give you a graphical user interface to
program your bot. There are no-code chatbot frameworks that abstract the
declarative chatbot programming language with an interactive graphical
representation of the dialog graph or flow diagram that you can modify with
your mouse. These no-code frameworks usually include a dialog engine that
can execute your chatbot without you ever having to see or edit the
underlying data. In the impact world, an open source platform sponsored by
UNICEF, RapidPro,
[
34
]
 served as a core for several chatbot platforms, such as
Weni, Textit and Glific, that are all used for impact purposes. In RapidPro,
you can build your dialogs in a graphical user interface. You can also easily
import and export the content using open standard file formats which is
helpful when you want to translate the content from one natural language to
another for a multilingual chatbot. ManyChat and Landbot are two closed
source no-code chatbot builders that have similar functionality.
But if you’ve read this far, you probably have ideas for more sophisticated
chatbots than what’s possible in a no-code platform. So you will probably
need a chatbot programming language to make your vision a reality. Of
course, you can specify your bot "stack" in Python by directly employing the
skills you learned in this book. But if you want to build a scalable and
maintainable chatbot you’ll need a chatbot framework that uses a chatbot
design language or data structure that you understand. You want a language
that makes sense to you so that you can quickly get the conversation design
you have in your head embedded in a working chatbot. In this section, you
will learn of several different frameworks that can help you make your
chatbot dreams come true.
Using the tools described here, you can build a bot that can serve you (and
maybe a few friends, or even more people if you’re lucky) if deployed on a
server or in a cloud. However, if you want to build a chatbot that servers
hundreds or thousands of users, you need a more robust, scalable system.
Luckily, there are frameworks available that allow you to focus on building
your bot while taking care of the challenges that come with the need to build
a production-grade system. We will now discuss three popular open-source
Python chatbot frameworks for building chatbots with configurable NLP
capabilities: Rasa, LangChain, and qary.
12.5.1 Building an intent-based chatbot with Rasa
Rasa is an open-source conversational framework that started back in 2016
and today is used to create thousands of bots in various languages around the
world. Unlike many commercial frameworks, that create a drag-and-drop
interface to create the dialog trees we discussed in the previous section,
RASA took a radically different approach to organizing multi-step
conversations.
The basic units of a conversation in RASA are a user intent and a bot action -
which can be as simple as a pre-programmed utterance or a complex action
programmed in Python that results in interaction with other systems - such as
saving or retrieving data from a database, or invoking a Web API. By
chaining these building blocks into sequences - called Stories - RASA allows
you to pre-program dialog scenarios in a streamlined way. All this
information is stored in YAML files (YAML stands for Yet Another Markup
Language), each type of components in its own file.
But enough with the theoretical explanation - let’s get your hands dirty and
build your first RASA chatbot. First, let’s decide what dialog we want to
implement - based on our conversation diagram for the math tutor bot, let’s
implement the following short dialog:
USER: Hello
BOT: Well, hello there. Thanks for checking out Rori, a math tutor chatbot. Chatting with Rori helps students improve their math skills. And it's fun too!
BOT: Are you a parent (or guardian) or are you a student?
USER: I'm a parent.
BOT: For your child to use Rori, we need permission from the parent or guardian. Do you agree to give your child permission to chat with Rori on this Whatsapp number?
USER: I agree
BOT: Thank you for giving permission for your child to chat with Rori.
When your child is ready to start, please give them this phone and have them type "ready".
To create your bot, you will need to install 
rasa
 package (if you’re working
in 
nlpia2
 environment, it is already installed when you install the project).
Then, you can go to the directory you want to create the project in and run in
your command line:
$ rasa init
The installation wizard will guide you through creating a new project and
even offer you to train an initial model. Let it do that, and then you can even
chat with a simple chatbot the wizard initialized for you.
Let’s now dive into the structure of our project and understand how to build a
dialog like you’ve just had. Here is the directory structure you should see in
the project’s folder:
├───.rasa
│   └───cache
│       ├───...
├───actions
│   └───__pycache__
├───data
├───models
└───tests
The directory we are most interested in is the 
data
 directory. It contains the
files that define the data that is used to train the chatbot’s NLU model. First,
there’s the 
nlu.yml
 file, which contains the intents and examples of user
utterances that are used to train the intent recognition model. So let’s start
creating the intents that are used in our dialog. For every intent you want to
define, you need to provide a name and a list of examples of utterances that
belong to this intent.
For our short dialog, we need to understand the user’s greeting, their role
(parent or student), and their agreement to give permission to their child to
use the chatbot.
version
: 
"
3.1
"
nlu
:
- 
intent: greet
  
examples
: 
|
 - hey - hello - hi
- 
intent: parent
 - I am a parent - Parent - I'm a mom to 12 year old
- 
intent: agree
...
Pretty straightforward, right? RASA will warn if you have too few examples
for a particular intent, and recommends at least 7-10 utterance examples per
intent.
The next file you should look at is 
domain.yml
account. When text message chatbots came onto the scene most continued to
follow this dark pattern of non-cooperative conversation, trying your patience
and preventing you from creating cost for the business. The more advanced
NLP skills you have learned in this book now give you the power to build
chatbots that can simulate intelligent conversation and do useful work for you
and your organization.
The chatbot boom is not over yet. You are about to learn all the ways they
can be used to improve your life or your business.
12.1 Chatbots are everywhere
Chatbots are everywhere. Here are some examples to help you dream up your
own projects.
Virtual assistants
: Dicio (Google Assistant), Lyra (Siri) and MyCroft
(Alexa) can help you accomplish small tasks such as checking the
weather, calling a friend, launching an app, setting a reminder, playing
music, or turning on the lights.
Entertainment
: Chatbots in video games and websites promoting movies
are often used to keep you engaged in a fictional storyline. You can
measure how well an entertainment chatbot is doing by how long the
user is willing to interact with the chatbot and how often they suspend
their disbelief that they are interacting with a human.
Healthcare
: Depending on the regulations in your country, chatbots can
often answer your health-related questions, schedule an appointment for
you, or even give a preliminary diagnosis. Mental health chatbots, such
as Woebot 
[
4
]
 and Wysa,
[
5
]
 even provide therapeutic exercises that can
decrease depression and anxiety.
[
6
]
Impact
: Nonprofits and social businesses use chatbots to help people in
need. Often they leverage popular messaging channels like SMS and
WhatsApp to reach people in underserved communities where mobile
messaging is their main access to the Internet.
Operations (ChatOps)
: Businesses often use chatbots to increase team
productivity and job satisfaction. You can build chatbots that interact
with you on Telegram or WhatsApp to help you monitor and control
your software. And, if you’re lucky, your boss at work might use a
chatbot to onboard and train you, or even publicly recognize you when
you help a teammate learn something new.
Advertisement and Sales
: Search engines on corporate websites often
use chatbots to steer you towards advertisements and products they want
you to purchase or promote. Behind the scenes these bots are often used
to distract and 
engage
 you on (anti)social networks.
Customer (dis)service
: Machines have been replacing humans at
customer service call centers and chat message interfaces for decades.
Most large corporations do not allow you to interact with a human until
you first satisfy their chatbot gatekeepers.
The authors of this book founded Tangible AI to help nonprofits,
governments, and individual makers create impact chatbots.
[
7
]
 Impact
chatbots help people in underserved communities, from new immigrants in
the United States to teens in the Global South. We’ve built chatbots that help
people learn math, overcome imposter syndrome, learn new languages, evade
human traffickers, and even start a small business in a developing country. A
contributing author and Tangible AI volunteer, Vishvesh Bhat, has even
founded a startup of his own to build a chatbot that helps US college students
learn and reason about their course material.
[
8
]
Next, you will learn how to build your own chatbots to bring a positive
impact to your community or business.
[
9
]
 
[
10
]
12.1.1 Different chatbots, same tools
As diverse as the chatbot examples in this section seem to be, they all
leverage the same NLP tools and techniques that you have learned in this
book. All the previous chapters have been building up your skills and toolbox
so you can assemble a chatbot. Here are some of the NLP skills you’ve
learned that will help you build chatbots:
Chapter 6
: Embedding words and phrases into semantic vectors (from
Chapter 6) to recognize a chatbot user’s intent
Chapter 8
: Creating more meaningful embedding vectors of chat
messages using LSTMs and language models such as BERT.
Chapter 9
: Translating between languages to help your users interact
with your chatbot in their native language.
Chapter 10
: Semantic search and automatic text generation to respond to
chat messages without having to craft responses by hand.
Chapter 11
: Extracting relationships between real-world entities from
text to help your chatbot reason about a users' requests and maintain the
conversation context.
Figure 
Figure 12. 1
 shows how all these pieces fit together to create a
chatbot.
Figure 12.1 Chatbot flow diagram
Before you jump into assembling a chatbot system from all these tools and
libraries, you need to think about what you want your chatbot to talk about.
You need to design a conversation.
12.1.2 Conversation design
As chatbot technology gained more and more popularity in the last decade, so
did the field of conversation design. Conversation design is a branch of user
interaction (UI) design that deals specifically with designing engaging
dialogs. This section will help you get started, and when you’re ready to dive
deeper you can dig into more detailed resources wuch as as Andrew Freed’s
excellent 
Conversational AI
 book.
[
11
]
For every chatbot project you will work your way through four stages:
1
. 
Define your chatbot’s goal and the problem it solves. What does success
look like? How will you tell when your chatbot is doing a good job?
2
. 
Think about your users. Who will benefit from using your chatbot?
What do they need? Where will your users be when they use your
chatbot? What triggered them to engage in the conversation?
3
. 
Draft an imaginary conversation between the user and your chatbot. This
is called the "happy path" or "happy conversation." You might even go
as far as "act it out" with a colleague or a friend.
4
. 
Diagram a conversation tree. After drafting several happy conversations
with your chatbot, you will notice patterns that you can generalize from
to create a 
conversation diagram
 — a flow chart showing several
possible conversations between the user and the chatbot.
5
. 
Choose the NLP algorithms from Figure 
Figure 12. 1
 that you or your
teammates will need to implement in software in order for your chatbot
to generate responses at every branch in your dialog tree.
Think about the example of a math tutor bot. The goal is pretty clear, you
want to teach math to middle school children. However, when you start
thinking about the users in step 2, you realize that you cannot assume that the
child would be the person contacting your bot first. This is what the Rori
project experienced in low-income countries, where young children rarely
own a phone. Your younger users will often borrow someone else’s phone or
computer. So your chatbot may not be able to send homework reminders or
other push notifications to the users' phone.
Another important thing to consider when dealing with children is that you
need to obtain a parent or guardian’s consent before allowing your chatbot to
interact directly with a child. You will need to comply will all the child
protection laws in the countries where your chatbot will be used, including
mandatory reporting of 
safeguarding disclosures
 by your users. If a child
mentions that they are being abused or are considering self-harm you will
want to detect and report those disclosures. No matter what your chatbot’s
goals are, when your users indicate that they may be in danger, you will want
your chatbot to detect and report these interactions to you or the appropriate
authorities. So your math tutor chatbot will need an intent classifier that can
categorize the messages your users send to the chatbot. The open source
MathText
[
12
]
 and 
Maitag
[
13
]
 projects give you pretrained mulitlabel classifiers
and labeled datasets for intent recognition, including the intents required for
the Rori project.
expressions find the closest grammar matches among a list of possible
grammar rules (regular expressions) instead of exact matches by ignoring
some maximum number of insertion, deletion, and substitution errors.
However, expanding the breadth and complexity of behaviors for pattern-
matching chatbots requires a lot of difficult human development work. Even
the most advanced grammar-based chatbots, built and maintained by some of
the largest corporations on the planet (Google, Amazon, Apple, Microsoft),
remain in the middle of the pack for depth and breadth of chatbot IQ.
A lot of powerful things can be done with shallow NLP. And little, if any,
human supervision (labeling or curating of text) is required. Often a machine
can be left to learn perpetually from its environment (the stream of words it
can pull from Twitter or some other source).
[
67
]
 We show you how to do this
in Chapter 6.
1.11 Natural language IQ
Like human brainpower, the power of an NLP pipeline cannot be easily
gauged with a single IQ score without considering multiple "smarts"
dimensions. A common way to measure the capability of a robotic system is
along the dimensions of behavior complexity and the degree of human
supervision required. But for a natural language processing pipeline, the goal
is to build systems that fully automate the processing of natural language,
eliminating all human supervision (once the model is trained and deployed).
So a better pair of IQ dimensions should capture the breadth and depth of the
complexity of the natural language pipeline.
A consumer product chatbot or virtual assistant like Alexa or Allo is usually
designed to have extremely broad knowledge and capabilities. However, the
logic used to respond to requests tends to be shallow, often consisting of a set
of trigger phrases that all produce the same response with a single if-then
decision branch. Alexa (and the underlying Lex engine) behave like a single
layer, flat tree of (if, elif, elif, …) statements.
[
68
]
 Google Dialogflow (which
was developed independently of Google’s Allo and Google Assistant) has
similar capabilities to Amazon Lex, Contact Flow, and Lambda, but without
the drag-and-drop user interface for designing your dialog tree.
On the other hand, the Google Translate pipeline (or any similar machine
translation system) relies on a deep tree of feature extractors, decision trees,
and knowledge graphs connecting bits of knowledge about the world.
Sometimes these feature extractors, decision trees, and knowledge graphs are
explicitly programmed into the system, as in Figure 1.5. Another approach
rapidly overtaking this "hand-coded" pipeline is the deep learning data-driven
approach. Feature extractors for deep neural networks are learned rather than
hard-coded, but they often require much more training data to achieve the
same performance as intentionally designed algorithms.
You will use both approaches (neural networks and hand-coded algorithms)
as you incrementally build an NLP pipeline for a chatbot capable of
conversing within a focused knowledge domain. This will give you the skills
you need to accomplish the natural language processing tasks within your
industry or business domain. Along the way you will probably get ideas
about how to expand the breadth of things this NLP pipeline can do. Figure
1.6 puts the chatbot in its place among the natural language processing
systems that are already out there. Imagine the chatbots you have interacted
with. Where do you think they might fit in a plot like this? Have you
attempted to gauge their intelligence by probing them with difficult questions
or something like an IQ test? Try asking a chatbot something ambiguous that
requires common sense logic and the ability to ask clarifying questions, such
as "What’s larger, the sun or a nickel?"
[
69
]
 you will get a chance to do exactly
that in later chapters, to help you decide how your chatbot stacks up against
some of the others in this diagram.
Figure 1.9 2D IQ of some natural language processing systems
As you progress through this book, you will be building the elements of a
chatbot. Chatbots require all the tools of NLP to work well:
Feature extraction (usually to produce a vector space model)
Information extraction to be able to answer factual questions
Semantic search to learn from previously recorded natural language text
or dialog
Natural language generation to compose new, meaningful statements
Machine learning gives us a way to trick machines into behaving as if we had
spent a lifetime programming them with hundreds of complex regular
expressions or algorithms. We can teach a machine to respond to patterns
similar to the patterns defined in regular expressions by merely providing it
examples of user statements and the responses we want the chatbot to mimic.
And the "models" of language, the FSMs, produced by machine learning, are
much better. They are less picky about mispelings and typoz.
And machine learning NLP pipelines are easier to "program." We do not
have to anticipate every possible use of symbols in our language. We just
have to feed the training pipeline with examples of the phrases that match and
with example phrases that do not match. As long as we label the example
phrases during training so that the chatbot knows which is which, it will learn
to discriminate between them. And there are even machine learning
approaches that require little if any "labeled" data.
We have given you some exciting reasons to learn about natural language
processing. You want to help save the world, do you not? And we have
attempted to pique your interest with some practical NLP applications that
are revolutionizing the way we communicate, learn, do business, and even
think. It will not be long before you are able to build a system that
approaches human-like conversational behavior. And you should be able to
see in upcoming chapters how to train a chatbot or NLP pipeline with any
domain knowledge that interests you — from finance and sports to
psychology and literature. If you can find a corpus of writing about it, then
you can train a machine to understand it.
This book is about using machine learning to build smart text-reading
machines without you having to anticipate all the ways people can say things.
Each chapter incrementally improves on the basic NLP pipeline for the
chatbot introduced in this chapter. As you learn the tools of natural language
processing, you will be building an NLP pipeline that can not only carry on a
conversation but help you accomplish your goals in business and in life.
1.12 Test yourself
Chapter 1 review questions
Here are some review questions for you to test your understanding:
1
. 
Why is NLP considered to be a core enabling feature for AGI (human-
like AI)?
2
. 
Why do advanced NLP models tend to show significant discriminatory
biases?
3
. 
How is it possible to create a prosocial chatbot using training data from
sources that include antisocial examples?
4
. 
What are 4 different approaches or architectures for building a chatbot?
5
. 
How is NLP used within a search engine?
6
. 
Write a regular expression to recognize your name and all the variations
on its spelling (including nicknames) that you’ve seen.
7
. 
Write a regular expression to try to recognize a sentence boundary
(usually a period ("."), question mark "?", or exclamation mark "!")
tip
Active learning, quizzing yourself with questions such as these, is a fast way
to gain deep understanding of any new topic. It turns out, this same approach
is effective for machine learning and model evaluation as well.footnote:
[Suggested answers are provided within the Python packages 
nlpia
(
https://gitlab.com/tangibleai/nlpia
) and 
qary
(
https://gitlab.com/tangibleai/qary
) where they are used to evaluate advanced
NLP models for reading comprehension and question answering. Pooja Sethi
will share active learning NLP insights on Substack
(
https://activelearning.substack.com
) and github (
for a particular intent, and recommends at least 7-10 utterance examples per
intent.
The next file you should look at is 
domain.yml
 in the main directory. Its first
section is quite straightforward: it defines the intents from the 
nlu.yml
 file
that the chatbot should be able to understand. Let’s add the intents we just
defined to this part.
version
: 
"
3.1
"
intents
:
  - 
greet
  - 
parent
  - 
agree
...
The next section includes the action the chatbot can take - in this simplest
example, the pre-programmed utterances that the chatbot can use in the
conversation.
responses
:
  
utter_welcome
:
  - 
text: "Well, hello there. Thanks for checking out Rori, a math tutor chatbot. Chatting with Rori helps students improve their math skills. And it's fun too!"
  
utter_parent_or_student
:
  - 
text: "Are you a parent (or guardian) or are you a student?"
  
utter_ask_permission
:
  - 
text: "For your child to use Rori, we need permission from the parent or guardian. Do you agree to give your child permission to chat with Rori on this Whatsapp number?"
  
utter_permission_granted
:
  - 
text: "Thank you for giving permission for your child to chat with Rori."
  
utter_invite_child
:
  - 
text: "When your child is ready to start, please give them this phone and have them type *ready*."
The 
domain.yml
 file concludes with chatbot configuration parameters, that
we won’t deal with in this book. What’s more exciting, is the file 
config.yml
that allows you to configure all the components of your chatbot’s NLU
pipeline. Let’s look at the pipeline that RASA loads for you by default:
pipeline
:
  - 
name: WhitespaceTokenizer
  - 
name: RegexFeaturizer
  - 
name: LexicalSyntacticFeaturizer
  - 
name: CountVectorsFeaturizer
  - 
name: CountVectorsFeaturizer
    
analyzer
: 
char_wb
    
min_ngram
: 
1
    
max_ngram
: 
4
  - 
name: DIETClassifier
    
epochs
: 
100
    
constrain_similarities
: 
true
  - 
name: EntitySynonymMapper
  - 
name: ResponseSelector
    
epochs
: 
100
    
constrain_similarities
: 
true
  - 
name: FallbackClassifier
    
threshold
: 
0.3
    
ambiguity_threshold
: 
0.1
You can see that your NLU pipeline uses a tokenizer based on whitespaces,
and quite a few different algorithms (featurizers) to turn the user’s utterance
into a vector to be classified by the model. The CountVectorsFeaturizes is our
old friend Bag of Words vectorizer, while others are additional enhancements
helping the intent recognition (like RegexFeaturizer) or entity detection (like
LexicalSyntacticFeaturizer).
[
35
]
 Finally, the main classifier RASA uses is
DIETClassifier, which is a neural network model that combines intent
recognition and entity detection in a single model.
Of course, you don’t have to stick with the default components of the
pipeline. For example, if you want to replace the BoW embeddings, RASA
also offers to use pretrained embeddings from libraries like spaCy or
HuggingFace Transformers. You can change single components inside the
pipeline, or build your own completely from scratch - RASA documentation
even provides recommendations on how to create a pipeline based on your
use case and training set.
[
36
]
Finally, the last important file we haven’t covered yet is the 
stories.yml
 file
in the 
data
 folder. In this file, you can actually define a conversation
scenario, by chaining intents and actions together. Let’s combine a simple
story for the dialog we created above:
- 
story: onboarding parent
  
steps
:
  - 
intent: greet
  - 
action: utter_welcome
  - 
action: utter_parent_or_student
  - 
intent: parent
  - 
action: utter_ask_permission
  - 
intent: agree
  - 
action: utter_permission_granted
  - 
action: utter_invite_child
This story defines one possible conversational sequence between the chatbot
and the user. If you want the conversation to follow a different route (for
example, if the user of the phone is a child), you can define another story and
add it to the 
stories.yml
 file. You can also interactively train your bot by
running 
rasa interactive
 command in your shell. That would open a
training interface that allows you to chat with your bot and define new
intents, actions, and stories on the fly.
One question you might be asking yourself - given all the ways people say
things, how does the conversation engine decide what action to take at every
turn? And how can you anticipate in advance all the ways that your users will
use your chatbot? In chapter 10 you learned how LLMs can chat about
virtually anything. But it’s not good enough to just redirect your users to
some other corporation’s LLM interface. You will need to be able to integrate
the chatbot into your existing NLP pipeline, such as the block diagram in
Figure 12. 1
. The LangChain package gives you a way to do exactly that.
12.5.2 Adding LLMs to your chatbot with LangChain
This is especially useful in education when you need to inspire students and
keep them engaged. Teachers do this naturally, by adjusting what they say
and how they say it based on feedback on how well the student understands
what they are saying. And teachers think about more than just "delivering a
message." They must think up new ideas and approaches, on the fly as
students pose interesting new questions. Inspiring students' curiosity with
Socratic questions and being responsive to their changing needs is a full-time
job.
It is virtually impossible to build a rule-based system that captures all the
things that teachers do to help students learn and grow. Students' needs are
too diverse and dynamic. This is why hybrid chatbots that integrate LLMs
have become the preferred way build production chatbots in virtually every
domain. An LLM can confidently and convincingly chat with your users on
virtually any topic. The key is to harness this power smartly so that it doesn’t
mislead your users, or worse.
Let’s build a bot with one of the popular tools for creating generative
chatbots - LangChain.
[
37
]
 Langchain is not quite a chatbot framework as are
Rasa or Rapidpro. Rather, it’s a library that abstracts away the particular API
of the LLM you want to use, allowing you to quickly experiment with
different models and different approaches to using them. It also uses As there
is currently no leading open-source framework leveraging LLMs, we