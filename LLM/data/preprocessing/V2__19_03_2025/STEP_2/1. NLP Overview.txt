# Natural Language Processing and Large Language Models

**Corso di Laurea Magistrale in Ingegneria Informatica - Lesson 1: NLP Overview**

**Nicola Capuano and Antonio Greco**

**DIEM – University of Salerno**

## Outline

*   What is Natural Language Processing
*   Applications of NLP
*   History of NLP

## What is Natural Language Processing?

### NLP in the Press

NLP is gaining prominence, as highlighted in various news outlets:

*   "New powerful AI bot creates angst among users: Are robots ready to take our jobs?"
*   "A Smarter Robot: A new chatbot shows rapid advances in artificial intelligence." - *The New York Times*
*   "What is ChatGPT, the viral social media AI?" - *The Washington Post*
*   "This AI chatbot is dominating social media with its frighteningly good essays." - *CNN*
*   "ChatGPT may be coming for our jobs. Here are the 10 roles that AI is most likely to replace." - *Business Insider*
*   "Microsoft co-founder Bill Gates: ChatGPT ‘will change our world'" - *Reuters*

### Importance of NLP

*   "Natural language is the most important part of Artificial Intelligence" - *John Searle, Philosopher*
*   "Natural language processing is a cornerstone of artificial intelligence, allowing computers to read and understand human language, as well as to produce and recognize speech" - *Ginni Rometty, IBM CEO*
*   "Natural language processing is one of the most important fields in artificial intelligence and also one of the most difficult" - *Dan Jurafsky, Professor of Linguistics and Computer Science at Stanford University*

### Definitions

*   "Natural language processing is the set of methods for making human language accessible to computers" - *Jacob Eisenstein*
*   "Natural language processing is the field at the intersection of computer science and linguistics" - *Christopher Manning*
*   "Make computers to understand natural language to do certain tasks humans can do such as translation, summarization, questions answering" - *Behrooz Mansouri*
*   "Natural language processing is an area of research in computer science and artificial intelligence concerned with processing natural languages such as English or Mandarin. This processing generally involves translating natural language into data that a computer can use to learn about the world. And this understanding of the world is sometimes used to generate natural language text that reflects that understanding." - *(Natural Language Processing in Action)*

### Natural Language Understanding

A subfield of NLP focused on transforming human language in a way that machines can process.

*   Involves extracting meaning, context, and intent from text.
*   Text is transformed into a numerical representation (embedding).

**Who uses Embeddings:**

*   **Search Engines:** to interpret the meaning behind search queries.
*   **Email Clients:** to detect spam and classify emails as important or not.
*   **Social Media:** to moderate posts and understand user sentiment.
*   **CRM Tools:** to analyze customer inquiries and route them.
*   **Recommender Systems:** to suggest articles, products, or content.

### Natural Language Generation

A subfield of NLP focused on generating human-like text.

*   Involves creating coherent, contextually appropriate text.
*   Based on a numerical representation of the meaning and sentiment you would like to convey.

**Applications:**

*   **Machine Translation:** translates text from one language to another.
*   **Text Summarization:** creation of concise summaries of long documents preserving key information.
*   **Dialogue Processing:** powers chatbots and virtual assistants to provide relevant responses in conversations.
*   **Content Creation:** generation of articles, reports, stories, poetry, ...

### Example: Conversational Agents

Conversational agents include:

*   Speech recognition
*   Language analysis
*   Dialogue processing
*   Information retrieval
*   Text to speech

**Example conversation:**

*   User: "Open the pod bay doors, Hal."
*   Hal: "I’m sorry, Dave, I’m afraid I can’t do that."
*   User: "What are you talking about, Hal?"
*   Hal: "I know that you and Frank were planning to disconnect me, and I'm afraid that's something I cannot allow to happen."

### Conversational Agents in Movies

Conversational agents are frequently featured in movies.

### NLP is Hard

"I made her duck… what does it mean?"

*   Duck: noun (waterfowl) or verb (getting down)?
*   Make: cook X or cause X to do Y?
*   Her: for her or belonging to her?

**Possible meanings:**

*   I cooked waterfowl for her
*   I cooked waterfowl belonging to her
*   I created the (plaster?) duck she owns
*   I caused her to quickly lower her head or body
*   I waved my magic wand and turned her into undifferentiated waterfowl

### Ambiguity

Natural language is extremely rich in form and structure and very ambiguous.

*   One input can mean many different things.
*   Many inputs can mean the same thing.

**Levels of ambiguity:**

*   **Lexical ambiguity:** different meanings of words.
*   **Syntactic ambiguity:** different ways to parse the sentence.
*   **Interpreting partial information:** how to interpret pronouns.
*   **Contextual information:** context of the sentence may affect the meaning of that sentence.

### Ambiguity Examples

*   "I saw bats… ?"
*   "Call me a cab… ?"

### NLP and Linguistics

NLP techniques draw on various aspects of linguistics:

*   **Phonetics:** understanding the physical sounds of speech and how they are produced and perceived.
*   **Morphology:** Knowledge of the structure and formation of words, including their meaningful components (morphemes).
*   **Syntax:** Understanding the rules and structures governing the arrangement of words in sentences.
*   **Semantics:** Insight into the meaning of words, phrases, and sentences.
*   **Pragmatics:** Understanding how context influences the interpretation of meaning.

### NLP vs Linguistics

**Linguistics:**

*   Focused on the study of language.
*   Explores the structure, meaning, and use of language.
*   May employ computational methods and tools as part of computational linguistics.

**NLP:**

*   Focused on providing computational capabilities that utilize human language.
*   Designs and implements algorithms to understand and generate human language.
*   Applies results from linguistics to develop practical applications.

## Applications of Natural Language Processing

### NLP Killer Applications

Key applications of NLP include:

*   Language translation
*   Email smart filtering
*   Smart assistant
*   Sentiment analysis
*   Document analysis
*   Chatbots
*   Semantic searches
*   Automatic summarization

### Applications by Business Sector

*   **Healthcare:**
    *   Process and interpret patient data, including medical records, to assist in diagnosis, treatment plans, and patient care.
    *   Extract information from unstructured data.
*   **Finance:**
    *   Analyze market sentiment, managing risk, detecting fraudulent activities.
    *   Generate insights from financial reports and news.
*   **E-commerce and Retail:**
    *   Personalized recommendations, improved search functionalities, and customer service chatbots.
    *   Sentiment analysis to gauge customer satisfaction and market trends.
*   **Legal:**
    *   Automate document analysis, aiding in legal research.
    *   Streamlining the review process for contracts and legal documentation.
*   **Customer Service:**
    *   Automate responses, guide users, and analyze feedback, improving efficiency.
*   **Education:**
    *   Automatic grading, provision of learning tools.
    *   Summarization and generation of educational materials.
*   **Automotive:**
    *   Intelligent navigation systems and voice-activated controls.
*   **Technology:**
    *   Assists in software development by generating code snippets and completing code.
    *   Enhances code quality through automated reviews and suggestions.
*   **Media and Entertainment:**
    *   Assist in generating scripts, articles, and creative writing.
    *   Enhance user engagement with interactive storytelling and personalized media experiences.

### Many Other Applications…

NLP is everywhere. It’s so ubiquitous that some of the examples may surprise you.

A search engine can provide more meaningful results if it indexes web pages or document archives in a way that takes into account the meaning of natural language text. Autocomplete uses NLP to complete your thought and is common among search engines and mobile phone keyboards. Many word processors, browser plugins, and text editors have spelling correctors, grammar checkers, concordance composers, and most recently, style coaches. Some dialogue engines (chatbots) use natural language search to find a response to their conversation partner’s message.

NLP pipelines that generate (compose) text can be used not only to compose short replies in chatbots and virtual assistants, but also to assemble much longer passages of text. The Associated Press uses NLP “robot journalists” to write entire financial news articles and sporting event reports. Bots can compose weather forecasts that sound a lot like what your hometown weather person might say, perhaps because human meteorologists use word processors with NLP features to draft scripts.

NLP spam filters in early email programs helped email overtake telephone and fax communication channels in the '90s. And the spam filters have retained their edge in the cat and mouse game between spam filters and spam generators for email, but may be losing in other environments like social networks. An estimated 20% of the tweets.

The following table categorizes NLP applications:

| Category        | Application                                       |
|-----------------|---------------------------------------------------|
| Search          | Web Documents, Autocomplete                       |
| Editing         | Spelling, Grammar, Style                           |
| Dialog          | Chatbot, Assistant, Scheduling                     |
| Writing         | Index, Concordance, Table of contents              |
| Email           | Spam filter, Classification, Prioritization          |
| Text mining     | Summarization, Knowledge extraction, Medical diagnoses |
| Law             | Legal inference, Precedent search, Subpoena classification |
| News            | Event detection, Fact checking, Headline composition  |
| Attribution     | Plagiarism detection, Literary forensics, Style coaching |
| Sentiment analysis | Community morale monitoring, Product review triage, Customer care |
| Behavior prediction | Finance, Election forecasting, Marketing           |
| Creative writing | Movie scripts, Poetry, Song lyrics                  |

### Hype Cycle

The Gartner Hype Cycle for Emerging Technologies (2023) positions NLP and related technologies within the innovation lifecycle, including:

*   API-Centric SaaS
*   Generative AI
*   AI TRiSM
*   WebAssembly (Wasm)
*   Federated Machine Learning
*   Industry Cloud Platforms
*   Internal Developer Portal
*   Cloud Sustainability
*   Homomorphic Encryption
*   Value Stream Management Platforms
*   Reinforcement Learning
*   Software Engineering
*   Cloud Development Environments
*   Graph Data Science
*   AI Simulation
*   Causal AI
*   Postquantum Cryptography
*   Neuro-Symbolic AI
*   Augmented FinOps
*   Generative Cybersecurity AI
*   Cybersecurity
*   Mesh Architecture

The cycle depicts stages from Innovation Trigger to Peak of Inflated Expectations, Trough of Disillusionment, Slope of Enlightenment, and finally, Plateau of Productivity. The estimated time to reach the plateau varies for each technology.

### NLP Market

NLP is a promising career option.

*   Growing demand for NLP applications.
*   Projected employment growth of 22% between 2020 and 2030.

The NLP market global forecast in USD Billions is projected to increase from 18.9 in 2023 to 61.8 in 2028.

*   North America
*   Europe
*   Asia Pacific
*   Middle East & Africa
*   Latin America

## History of NLP

### First Steps of NLP

NLP has had a history of ups and downs.

*   Influenced by the growth of computational resources and changes in approaches.

**1950's and 1960's**

*   The first application that sparked interest in NLP was machine translation.
*   The first machine translation systems used dictionary lookup and basic word order rules to produce translations.
*   The 1950s saw a lot of excitement: researchers predicted that machine translation can be solved in 3 years or so.

### Machine Translation in 50s

**Example:**

Given:

```
Dictionary: Red -> Rosso
            House -> Casa
```

Translate:

```
The red house -> Il rosso casa   (incorrect)
```

But it should be:

```
La casa rossa (correct)
```

Dictionary lookup alone is insufficient.

### How to deal with language ambiguity?

### Generative Grammars

**1957: Chomsky’s Generative Grammar**

*   A system of rules for generating all possible sentences in a language.
*   Enabled prediction of grammatical correctness.
*   Understanding of language structure.
*   Influenced research in machine translation.

**1966: The Reality Check**

*   Early translation systems fell short in effectiveness.
*   Limited by their inability to handle the ambiguity and complexity of natural language.

### ALPAC Report

**Automatic Language Processing Advisory Committee**

*   Established to assess advancements in computational linguistics.
*   The 1966 ALPAC report recommended halting research into machine translation.
*   Shift focus from developing end-to-end machine translation systems to enhancing tools that assist human translators.
*   It significantly impacted NLP and AI research, contributing to the first AI winter.

[https://www.mt-archive.net/50/ALPAC-1966.pdf](https://www.mt-archive.net/50/ALPAC-1966.pdf)

### ELIZA

A pioneering conversational agent.

*   Created by Joseph Weizenbaum in the 1960s.
*   Designed to simulate a conversation between a psychotherapist and a patient.

**Features and Limitations:**

*   Demonstrated the potential of computer-based conversation.
*   Utilized pattern matching and substitution to generate responses.
*   Limited in handling complex conversations.
*   Could not maintain context beyond a few exchanges.
*   Often produced irrelevant or repetitive responses.

[https://psych.fullerton.edu/mbirnbaum/psych101/eliza.htm](https://psych.fullerton.edu/mbirnbaum/psych101/eliza.htm)

### The Turing Test

"I propose to consider the question: can machines think? ... We can only see a short distance ahead, but we can see plenty there that needs to be done" - *Alan Turing, Computing Machinery and Intelligence, 1950*

**Turing Test aka The Imitation game:**

*   A human, a computer, an interrogator in a different room communicate via written messages.
*   The interrogator should classify the human and the machine.

### The Turing Test

**Capabilities for passing the Turing Test**

*   Natural Language Understanding to interpret user input
*   Knowledge Representation to draw on relevant information
*   Automated Reasoning to generate appropriate and logical responses
*   Natural Language Generation to produce human-like textual responses
*   Context Management to maintain and utilize context across multiple exchanges in a conversation
*   Adaptability and Learning to adapt responses based on user behavior and feedback

### The Turing Test

**Successes with Turing test**

*   A (controversial) success in 2014: a chatbot mimicking the answer of a 13 years old boy
*   Since then, other (controversial) successes

**Limitations of Turing Test**

*   Not reproducible
*   Is emulating humans necessary for achieving intelligence?
*   Many AI researchers have shifted focus to other benchmarks
*   Less commonly used today

### Raise of Symbolic Approaches

**1970's and 1980's:**

*   Programmers started creating structured representations of real-world information for computer understanding (ontologies)
*   Complex rule-based systems were developed for various NLP tasks, including parsing, morphology, semantics, reference, ...

**Main applications were:**

*   **Expert Systems:** mimicked human expertise in specific domains
*   **Information Retrieval:** enhanced search and data extraction

**Main limitations were:**

*   **Flexibility:** challenges in adapting to new or ambiguous contexts
*   **Scalability:** difficulty handling large-scale or diverse data

### Statistical Revolution

**1990's:**

*   The computing power increased substantially
*   Statistical models with simple representations started to outperform complex hand-coded linguistic rules
*   Learn patterns from data
*   Can handle variations and complexities in natural language
*   Large corpora became essential
*   Long Short-Term Memory (LSTM) networks was invented by Hochreiter and Schmidhuber in 1997

*"Whenever I fire a linguist, our machine translation performance improves" - Fred Jelinek, IBM*

### Advances in NLP

**2000's**

*   Increased Use of Neural Networks
*   Introduction of Word Embeddings
    *   Words are represented as dense vectors of numbers
    *   Words with similar meanings are associated with similar vectors
    *   Early algorithms struggled to efficiently learn these representations

**2006: launch of Google Translate**

*   The first commercially successful NLP system
*   Utilized statistical models to automatically translate documents

### Deep Learning Era

**2010's:**

*   LSTM and CNN became widely adopted for NLP
*   The availability of large text corpora enabled the training of increasingly complex models

**Word2Vec (2013):**

*   Efficient Estimation of Word Representations in Vector Space
*   The first algorithm to efficiently learn word embeddings
*   Enables semantic operations with word vector
*   Paved the way for more advanced models such as GloVe, fastText, ELMo, BERT, COLBERT, GPT, ...

### Deep Learning Era

**Sequence-to-Sequence Models (2014):**

*   Introduction of the encoder-decoder architecture:
    *   **Encoder:** Encodes the input into a context vector
    *   **Decoder:** Decodes the output from the context vector
*   Useful for automatic translation, question answering, text summarization, text generation, ...

**Example:**

```
The red house -> Context vector [0.3, 0.6, -0.2, ..., 0.1] -> La casa rossa
```

### Virtual Assistants

A Virtual Assistant performs a range of tasks or services based on user input in natural language.

Many VA were launched in 2010's:

*   2011: Siri launched by Apple on iOS devices
*   2014: Cortana introduced by Microsoft for Windows Phone
*   2014: Alexa launched by Amazon with the Echo, pioneering voice-controlled smart home
*   2015: Google Assistant introduced, integrating voice interaction with Android and Google Home

### Deep Learning Era

**Transformer (2017):**

*   **Attention Is All You Need**
*   Integration of attention mechanisms
*   Allows a greater passage of information between the decoder and the encoder
*   Defined and adopted by Google for the translator
*   It remains the dominant architecture in NLP today

*Diagram of Transformer Architecture*

### Large Language Models

After transformers, the next step was scaling...

*   LLM leverage extensive data and computational power to understand and generate human-like text

*   List of LLMs: GPT-4, ChatGPT, InstructGPT, Codex, Flan-PaLM, LLaMA, BLOOM, OPT, UL2, PaLM, Gopher, Chinchilla, Titan, Jurassic-1, Ernie 3.0, PanGu, etc.*

### LLM Applications

*   **Text Generation:** Producing articles, stories, and creative writing
*   **Machine Translation:** Translating between languages
*   **Chatbots:** Engaging in human-like conversations for customer support and interaction
*   **Code Generation:** Generating and suggesting code snippets, completing code, and assisting with programming tasks
*   **Question Answering:** Providing answers based on a given context or database
*   **Text Summarization:** Condensing long documents into concise summaries
*   **Writing Assistance:** Generating and completing text, improving grammar, and enhancing style

### Multimodal LLM

Integrate and process multiple types of data

*   **Image-to-Text:** generating descriptive text from images (CLIP)
*   **Text-to-Image:** creating images based on textual descriptions (DALL-E)
*   **Audio-to-Text:** converting spoken language into written text (Whisper)
*   **Text-to-Audio:** composing or generating audio, such as music, from textual descriptions (Jukebox)

### Multimodal LLM

Integrate and process multiple types of data

*   **Video-to-Text:** Generating textual descriptions or summaries from video content (VideoBERT)
*   **Text-to-Video:** Video content from textual descriptions (Sora)

Example Prompt: Photorealistic closeup video of two pirate ships battling each other as they sail inside a cup of coffee

## References

*   Natural Language Processing IN ACTION: Understanding, analyzing, and generating text with Python, Chapter 1
