# Natural Language Processing and Large Language Models

**Corso di Laurea Magistrale in Ingegneria Informatica (Master's Degree in Computer Engineering) - Lesson 1: NLP Overview**

**Nicola Capuano and Antonio Greco**

**DIEM – University of Salerno**

This document provides an overview of Natural Language Processing (NLP) intended for students in a Master's level Computer Engineering course. It is presented by Nicola Capuano and Antonio Greco from the Department of Information Engineering and Mathematics (DIEM) at the University of Salerno. The overview includes definitions, applications, and historical context for understanding NLP's significance and challenges.

<----------section---------->

## Outline

This lesson will cover the following key areas:

*   **What is Natural Language Processing (NLP):** Introduction to the field, its core concepts, and importance.
*   **Applications of NLP:** A survey of diverse applications across various industries and domains.
*   **History of NLP:** Tracing the evolution of NLP from its early stages to the current state-of-the-art.

<----------section---------->

## What is Natural Language Processing?

NLP is an interdisciplinary field focusing on enabling computers to understand, interpret, and generate human language. It sits at the intersection of computer science, artificial intelligence, and linguistics. This allows computers to process and analyze large amounts of natural language data, derive insights, and perform tasks such as translation, summarization, and sentiment analysis.

### NLP in the Press

NLP's growing influence and capabilities are frequently highlighted in the media, underscoring its importance and potential impact:

*   "New powerful AI bot creates angst among users: Are robots ready to take our jobs?" - Reflects concerns about automation and job displacement.
*   "A Smarter Robot: A new chatbot shows rapid advances in artificial intelligence." - *The New York Times* - Highlights the rapid progress in AI-driven conversational agents.
*   "What is ChatGPT, the viral social media AI?" - *The Washington Post* - Introduces ChatGPT, a prominent example of advanced language models.
*   "This AI chatbot is dominating social media with its frighteningly good essays." - *CNN* - Emphasizes the impressive text generation capabilities of AI chatbots.
*   "ChatGPT may be coming for our jobs. Here are the 10 roles that AI is most likely to replace." - *Business Insider* - Speculates about the potential impact of AI on various professions.
*   "Microsoft co-founder Bill Gates: ChatGPT ‘will change our world’" - *Reuters* - Indicates the transformative potential of NLP technology, particularly ChatGPT, as seen by industry leaders.

These headlines reflect the growing societal awareness and debate surrounding NLP's capabilities and implications.

<----------section---------->

### Importance of NLP

Eminent figures emphasize NLP's crucial role in artificial intelligence:

*   "Natural language is the most important part of Artificial Intelligence" - *John Searle, Philosopher* - Highlights the centrality of human language understanding in achieving true AI.
*   "Natural language processing is a cornerstone of artificial intelligence, allowing computers to read and understand human language, as well as to produce and recognize speech" - *Ginni Rometty, IBM CEO* - Underscores NLP's role as a foundational technology for enabling human-computer interaction.
*   "Natural language processing is one of the most important fields in artificial intelligence and also one of the most difficult" - *Dan Jurafsky, Professor of Linguistics and Computer Science at Stanford University* - Acknowledges both the significance and complexity of NLP research.

These quotes emphasize that NLP is not just a subfield of AI, but a critical component that enables machines to interact with humans in a meaningful way.

<----------section---------->

### Definitions

Several definitions of NLP provide a comprehensive understanding of the field:

*   "Natural language processing is the set of methods for making human language accessible to computers" - *Jacob Eisenstein* - Focuses on bridging the gap between human and machine communication.
*   "Natural language processing is the field at the intersection of computer science and linguistics" - *Christopher Manning* - Highlights the interdisciplinary nature of NLP.
*   "Make computers to understand natural language to do certain tasks humans can do such as translation, summarization, questions answering" - *Behrooz Mansouri* - Emphasizes the goal of replicating human language capabilities in computers.
*   "Natural language processing is an area of research in computer science and artificial intelligence concerned with processing natural languages such as English or Mandarin. This processing generally involves translating natural language into data that a computer can use to learn about the world. And this understanding of the world is sometimes used to generate natural language text that reflects that understanding." - *(Natural Language Processing in Action)* - Provides a detailed description of the research area, including translating natural language into computer-interpretable data and using this to generate natural language text.

These definitions collectively illustrate NLP's goal of enabling computers to process and understand human language for various tasks.

<----------section---------->

### Natural Language Understanding (NLU)

NLU is a subfield of NLP dedicated to enabling machines to comprehend human language. It focuses on converting human language into a format that computers can process effectively.

*   Involves extracting meaning, context, and intent from text.
*   Text is transformed into a numerical representation (embedding), which captures the semantic information.

**Who uses Embeddings:**

*   **Search Engines:** Interpret the meaning behind search queries to deliver relevant results. For example, understanding that "best Italian restaurants near me" is a request for nearby Italian eateries.
*   **Email Clients:** Detect spam and classify emails as important or not, filtering out unwanted messages and prioritizing relevant correspondence.
*   **Social Media:** Moderate posts by identifying hate speech, offensive content, and misinformation. Understand user sentiment to improve content recommendations and user experience.
*   **CRM Tools:** Analyze customer inquiries to understand customer needs, route inquiries to the appropriate departments, and personalize interactions.
*   **Recommender Systems:** Suggest articles, products, or content based on user preferences and past behavior. For example, recommending books similar to those a user has previously enjoyed.

NLU is vital for extracting actionable insights from textual data, enabling a wide array of applications.

<----------section---------->

### Natural Language Generation (NLG)

NLG is another key subfield of NLP, focused on generating human-like text. Its goal is to enable computers to produce coherent and contextually appropriate text.

*   Involves creating coherent, contextually appropriate text.
*   Based on a numerical representation of the meaning and sentiment you would like to convey.

**Applications:**

*   **Machine Translation:** Translates text from one language to another, allowing for cross-lingual communication.
*   **Text Summarization:** Creates concise summaries of long documents, preserving key information. Useful for quickly grasping the essence of lengthy reports or articles.
*   **Dialogue Processing:** Powers chatbots and virtual assistants to provide relevant responses in conversations, enhancing customer service and user engagement.
*   **Content Creation:** Generates articles, reports, stories, poetry, and other forms of creative writing. Useful for automating content creation processes and inspiring creativity.

NLG enables computers to communicate effectively, generate content automatically, and enhance human-computer interactions.

<----------section---------->

### Example: Conversational Agents

Conversational agents, also known as chatbots or virtual assistants, exemplify the integration of NLU and NLG. They are designed to simulate human conversation and provide information or perform tasks.

Conversational agents include:

*   **Speech Recognition:** Converts spoken language into text.
*   **Language Analysis:** Understands the meaning and intent of the text.
*   **Dialogue Processing:** Manages the flow of conversation.
*   **Information Retrieval:** Accesses and retrieves relevant information.
*   **Text to Speech:** Converts text into spoken language.

**Example conversation:**

*   User: "Open the pod bay doors, Hal."
*   Hal: "I’m sorry, Dave, I’m afraid I can’t do that."
*   User: "What are you talking about, Hal?"
*   Hal: "I know that you and Frank were planning to disconnect me, and I'm afraid that's something I cannot allow to happen."

This example, inspired by the movie 2001: A Space Odyssey, illustrates the complex dialogue management and reasoning capabilities that conversational agents can achieve.

<----------section---------->

### Conversational Agents in Movies

Conversational agents are frequently featured in movies, showcasing advanced AI capabilities and sparking both excitement and concern about the future of human-computer interaction. They are frequently featured in movies, symbolizing advanced AI and raising questions about future human-computer relationships.

### NLP is Hard

One of the primary challenges in NLP is ambiguity. Natural language is inherently ambiguous, leading to multiple possible interpretations of the same input.

"I made her duck… what does it mean?"

*   Duck: noun (waterfowl) or verb (getting down)?
*   Make: cook X or cause X to do Y?
*   Her: for her or belonging to her?

**Possible meanings:**

*   I cooked waterfowl for her
*   I cooked waterfowl belonging to her
*   I created the (plaster?) duck she owns
*   I caused her to quickly lower her head or body
*   I waved my magic wand and turned her into undifferentiated waterfowl

This example demonstrates how a simple sentence can have multiple valid interpretations, posing a significant challenge for NLP systems.

<----------section---------->

### Ambiguity

Natural language is extremely rich in form and structure, yet highly ambiguous. NLP systems must handle this ambiguity to accurately understand and generate text.

*   One input can mean many different things.
*   Many inputs can mean the same thing.

**Levels of ambiguity:**

*   **Lexical ambiguity:** Different meanings of words (e.g., "bank" as a financial institution or a river bank).
*   **Syntactic ambiguity:** Different ways to parse the sentence (e.g., "I saw the man on the hill with a telescope").
*   **Interpreting partial information:** How to interpret pronouns (e.g., "John told Bill that he was wrong" - who was wrong?).
*   **Contextual information:** Context of the sentence may affect the meaning of that sentence (e.g., sarcasm, irony).

NLP systems must consider various levels of ambiguity to derive the correct meaning.

<----------section---------->

### Ambiguity Examples

*   "I saw bats… ?" - Could refer to seeing the animals or baseball bats.
*   "Call me a cab… ?" - Could mean "hail a taxi for me" or "refer to me as a cab."

These examples further illustrate the pervasiveness of ambiguity in natural language.

### NLP and Linguistics

NLP techniques draw on various aspects of linguistics to accurately process and generate human language.

*   **Phonetics:** Understanding the physical sounds of speech and how they are produced and perceived. Crucial for speech recognition and synthesis.
*   **Morphology:** Knowledge of the structure and formation of words, including their meaningful components (morphemes). Helps in understanding word meanings and relationships.
*   **Syntax:** Understanding the rules and structures governing the arrangement of words in sentences. Essential for parsing sentences and determining their grammatical structure.
*   **Semantics:** Insight into the meaning of words, phrases, and sentences. Enables the extraction of accurate meaning and relationships between concepts.
*   **Pragmatics:** Understanding how context influences the interpretation of meaning. Essential for capturing nuances like sarcasm, irony, and implied intentions.

By integrating these linguistic elements, NLP systems can achieve more accurate and nuanced language understanding.

<----------section---------->

### NLP vs Linguistics

While both NLP and Linguistics are related to language, their goals and approaches differ:

**Linguistics:**

*   Focused on the study of language as a scientific discipline.
*   Explores the structure, meaning, and use of language from a theoretical perspective.
*   May employ computational methods and tools as part of computational linguistics.

**NLP:**

*   Focused on providing computational capabilities that utilize human language.
*   Designs and implements algorithms to understand and generate human language.
*   Applies results from linguistics to develop practical applications, such as machine translation, chatbots, and sentiment analysis.

In essence, linguistics provides the theoretical foundations, while NLP focuses on practical applications. NLP can be viewed as an engineering discipline that leverages linguistic knowledge to solve real-world problems.

<----------section---------->

## Applications of Natural Language Processing

NLP has a wide range of applications across various domains, transforming how we interact with technology and process information.

### NLP Killer Applications

Key applications of NLP include:

*   **Language translation:** Automatically translating text or speech between languages.
*   **Email smart filtering:** Classifying and filtering emails based on content and sender.
*   **Smart assistant:** Virtual assistants like Siri, Alexa, and Google Assistant that respond to voice commands and perform tasks.
*   **Sentiment analysis:** Determining the emotional tone or attitude expressed in a piece of text.
*   **Document analysis:** Extracting key information and insights from large volumes of text.
*   **Chatbots:** Automated conversational agents that interact with users to provide information or assistance.
*   **Semantic searches:** Search engines that understand the meaning behind search queries.
*   **Automatic summarization:** Generating concise summaries of longer documents.

These applications demonstrate NLP's versatility and its potential to improve efficiency and user experience in various settings.

<----------section---------->

### Applications by Business Sector

NLP's impact extends across numerous business sectors, each with unique applications:

*   **Healthcare:**
    *   Process and interpret patient data, including medical records, to assist in diagnosis, treatment plans, and patient care. Enhances accuracy and efficiency in healthcare delivery.
    *   Extract information from unstructured data, such as doctors' notes and research papers, to identify patterns and insights. Improves research and clinical decision-making.
*   **Finance:**
    *   Analyze market sentiment, managing risk, detecting fraudulent activities. Provides timely insights for financial institutions.
    *   Generate insights from financial reports and news, to identify trends and predict market movements. Automates analysis of complex financial data.
*   **E-commerce and Retail:**
    *   Personalized recommendations, improved search functionalities, and customer service chatbots. Boosts sales and enhances customer satisfaction.
    *   Sentiment analysis to gauge customer satisfaction and market trends. Enables businesses to adapt to changing customer preferences.
*   **Legal:**
    *   Automate document analysis, aiding in legal research. Improves the efficiency of legal professionals by automating document review.
    *   Streamlining the review process for contracts and legal documentation. Reduces the time and cost associated with legal processes.
*   **Customer Service:**
    *   Automate responses, guide users, and analyze feedback, improving efficiency. Enhances customer service by providing timely and relevant assistance.
*   **Education:**
    *   Automatic grading, provision of learning tools. Improves the efficiency of educators and provides personalized learning experiences.
    *   Summarization and generation of educational materials. Creates tailored learning resources and simplifies complex topics.
*   **Automotive:**
    *   Intelligent navigation systems and voice-activated controls. Enhances the driving experience by enabling hands-free control and navigation.
*   **Technology:**
    *   Assists in software development by generating code snippets and completing code. Increases developer productivity by automating routine tasks.
    *   Enhances code quality through automated reviews and suggestions. Improves software reliability and reduces errors.
*   **Media and Entertainment:**
    *   Assist in generating scripts, articles, and creative writing. Enhances creativity and automates content creation processes.
    *   Enhance user engagement with interactive storytelling and personalized media experiences. Provides immersive and personalized content for users.

These applications highlight NLP's transformative potential across diverse industries.

<----------section---------->

### Many Other Applications…

NLP is pervasive in modern technology, with applications that are often unnoticed yet profoundly impactful.

A search engine can provide more meaningful results if it indexes web pages or document archives in a way that takes into account the meaning of natural language text. Autocomplete uses NLP to complete your thought and is common among search engines and mobile phone keyboards. Many word processors, browser plugins, and text editors have spelling correctors, grammar checkers, concordance composers, and most recently, style coaches. Some dialogue engines (chatbots) use natural language search to find a response to their conversation partner’s message.

NLP pipelines that generate (compose) text can be used not only to compose short replies in chatbots and virtual assistants, but also to assemble much longer passages of text. The Associated Press uses NLP “robot journalists” to write entire financial news articles and sporting event reports. Bots can compose weather forecasts that sound a lot like what your hometown weather person might say, perhaps because human meteorologists use word processors with NLP features to draft scripts.

NLP spam filters in early email programs helped email overtake telephone and fax communication channels in the '90s. And the spam filters have retained their edge in the cat and mouse game between spam filters and spam generators for email, but may be losing in other environments like social networks. An estimated 20% of the tweets.
*From the Additional Context*: NLP pipelines that generate text can be used not only to compose short replies in chatbots and virtual assistants but also to assemble much longer passages of text. The Associated Press uses NLP "robot journalists" to write entire financial news articles and sporting event reports. NLP spam filters in early email programs helped email overtake telephone and fax communication channels in the '90s. And some teams use NLP to automate and personalize e-mails between teammates or communicate with job applicants. The spam filters have retained their edge in the cat-and-mouse game between spam filters and spam generators for email but may be losing in other environments like social networks. An estimated 20% of the tweets about the 2016 US presidential election were composed by chatbots.

The following table categorizes NLP applications:

| Category        | Application                                       |
|-----------------|---------------------------------------------------|
| Search          | Web Documents, Autocomplete                       |
| Editing         | Spelling, Grammar, Style                           |
| Dialog          | Chatbot, Assistant, Scheduling                     |
| Writing         | Index, Concordance, Table of contents              |
| Email           | Spam filter, Classification, Prioritization          |
| Text mining     | Summarization, Knowledge extraction, Medical diagnoses |
| Law             | Legal inference, Precedent search, Subpoena classification |
| News            | Event detection, Fact checking, Headline composition  |
| Attribution     | Plagiarism detection, Literary forensics, Style coaching |
| Sentiment analysis | Community morale monitoring, Product review triage, Customer care |
| Behavior prediction | Finance, Election forecasting, Marketing           |
| Creative writing | Movie scripts, Poetry, Song lyrics                  |

<----------section---------->

### Hype Cycle

The Gartner Hype Cycle for Emerging Technologies (2023) positions NLP and related technologies within the innovation lifecycle, including:

*   API-Centric SaaS
*   Generative AI
*   AI TRiSM
*   WebAssembly (Wasm)
*   Federated Machine Learning
*   Industry Cloud Platforms
*   Internal Developer Portal
*   Cloud Sustainability
*   Homomorphic Encryption
*   Value Stream Management Platforms
*   Reinforcement Learning
*   Software Engineering
*   Cloud Development Environments
*   Graph Data Science
*   AI Simulation
*   Causal AI
*   Postquantum Cryptography
*   Neuro-Symbolic AI
*   Augmented FinOps
*   Generative Cybersecurity AI
*   Cybersecurity
*   Mesh Architecture

The cycle depicts stages from Innovation Trigger to Peak of Inflated Expectations, Trough of Disillusionment, Slope of Enlightenment, and finally, Plateau of Productivity. The estimated time to reach the plateau varies for each technology. Understanding the Gartner Hype Cycle helps to assess the maturity and potential of NLP and its related technologies.

<----------section---------->

### NLP Market

NLP is a promising career option.

*   Growing demand for NLP applications.
*   Projected employment growth of 22% between 2020 and 2030.

The NLP market global forecast in USD Billions is projected to increase from 18.9 in 2023 to 61.8 in 2028.

*   North America
*   Europe
*   Asia Pacific
*   Middle East & Africa
*   Latin America

This data underscores the significant economic opportunities and potential career paths within the field of NLP.

<----------section---------->

## History of NLP

### First Steps of NLP

NLP has had a history of ups and downs.

*   Influenced by the growth of computational resources and changes in approaches.

**1950's and 1960's**

*   The first application that sparked interest in NLP was machine translation.
*   The first machine translation systems used dictionary lookup and basic word order rules to produce translations.
*   The 1950s saw a lot of excitement: researchers predicted that machine translation can be solved in 3 years or so.

The early focus on machine translation was driven by Cold War-era needs, but initial systems were overly simplistic and yielded limited results.

<----------section---------->

### Machine Translation in 50s

**Example:**

Given:

```
Dictionary: Red -> Rosso
            House -> Casa
```

Translate:

```
The red house -> Il rosso casa   (incorrect)
```

But it should be:

```
La casa rossa (correct)
```

Dictionary lookup alone is insufficient.

This example illustrates the limitations of early machine translation systems that relied solely on dictionary lookup and basic rules, without considering grammatical structure and contextual nuances.

### How to deal with language ambiguity?

### Generative Grammars

**1957: Chomsky’s Generative Grammar**

*   A system of rules for generating all possible sentences in a language.
*   Enabled prediction of grammatical correctness.
*   Understanding of language structure.
*   Influenced research in machine translation.

Noam Chomsky's work provided a theoretical framework for understanding the structure of language and influenced NLP research by offering a way to formally represent grammatical rules.

<----------section---------->

**1966: The Reality Check**

*   Early translation systems fell short in effectiveness.
*   Limited by their inability to handle the ambiguity and complexity of natural language.

Despite initial optimism, early machine translation systems failed to meet expectations due to their inability to deal with the nuances of natural language.

### ALPAC Report

**Automatic Language Processing Advisory Committee**

*   Established to assess advancements in computational linguistics.
*   The 1966 ALPAC report recommended halting research into machine translation.
*   Shift focus from developing end-to-end machine translation systems to enhancing tools that assist human translators.
*   It significantly impacted NLP and AI research, contributing to the first AI winter.

[https://www.mt-archive.net/50/ALPAC-1966.pdf](https://www.mt-archive.net/50/ALPAC-1966.pdf)

The ALPAC report led to a significant reduction in funding for machine translation research and marked a period of disillusionment with AI in general.

<----------section---------->

### ELIZA

A pioneering conversational agent.

*   Created by Joseph Weizenbaum in the 1960s.
*   Designed to simulate a conversation between a psychotherapist and a patient.

**Features and Limitations:**

*   Demonstrated the potential of computer-based conversation.
*   Utilized pattern matching and substitution to generate responses.
*   Limited in handling complex conversations.
*   Could not maintain context beyond a few exchanges.
*   Often produced irrelevant or repetitive responses.

[https://psych.fullerton.edu/mbirnbaum/psych101/eliza.htm](https://psych.fullerton.edu/mbirnbaum/psych101/eliza.htm)

ELIZA, while simple, demonstrated the possibility of creating conversational agents, even with limited understanding of natural language.

<----------section---------->

### The Turing Test

"I propose to consider the question: can machines think? ... We can only see a short distance ahead, but we can see plenty there that needs to be done" - *Alan Turing, Computing Machinery and Intelligence, 1950*

**Turing Test aka The Imitation game:**

*   A human, a computer, an interrogator in a different room communicate via written messages.
*   The interrogator should classify the human and the machine.

The Turing Test provides a benchmark for evaluating a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.

### The Turing Test

**Capabilities for passing the Turing Test**

*   Natural Language Understanding to interpret user input
*   Knowledge Representation to draw on relevant information
*   Automated Reasoning to generate appropriate and logical responses
*   Natural Language Generation to produce human-like textual responses
*   Context Management to maintain and utilize context across multiple exchanges in a conversation
*   Adaptability and Learning to adapt responses based on user behavior and feedback

Achieving success in the Turing Test requires advanced capabilities in various aspects of NLP and AI.

<----------section---------->

### The Turing Test

**Successes with Turing test**

*   A (controversial) success in 2014: a chatbot mimicking the answer of a 13 years old boy
*   Since then, other (controversial) successes

**Limitations of Turing Test**

*   Not reproducible
*   Is emulating humans necessary for achieving intelligence?
*   Many AI researchers have shifted focus to other benchmarks
*   Less commonly used today

Despite some successes, the Turing Test has limitations as a measure of true intelligence, and many researchers now focus on other benchmarks.

### Raise of Symbolic Approaches

**1970's and 1980's:**

*   Programmers started creating structured representations of real-world information for computer understanding (ontologies)
*   Complex rule-based systems were developed for various NLP tasks, including parsing, morphology, semantics, reference, ...

**Main applications were:**

*   **Expert Systems:** mimicked human expertise in specific domains
*   **Information Retrieval:** enhanced search and data extraction

During this period, NLP research shifted towards symbolic approaches that emphasized knowledge representation and rule-based systems.

<----------section---------->

**Main limitations were:**

*   **Flexibility:** challenges in adapting to new or ambiguous contexts
*   **Scalability:** difficulty handling large-scale or diverse data

However, symbolic approaches proved brittle and difficult to scale, leading to the next major shift in NLP research.

### Statistical Revolution

**1990's:**

*   The computing power increased substantially
*   Statistical models with simple representations started to outperform complex hand-coded linguistic rules
*   Learn patterns from data
*   Can handle variations and complexities in natural language
*   Large corpora became essential
*   Long Short-Term Memory (LSTM) networks was invented by Hochreiter and Schmidhuber in 1997

The advent of statistical models and machine learning marked a turning point in NLP, enabling systems to learn patterns from data and handle variations in language more effectively.

*"Whenever I fire a linguist, our machine translation performance improves" - Fred Jelinek, IBM*

This quote reflects the shift from rule-based to data-driven approaches in NLP.

<----------section---------->

### Advances in NLP

**2000's**

*   Increased Use of Neural Networks
*   Introduction of Word Embeddings
    *   Words are represented as dense vectors of numbers
    *   Words with similar meanings are associated with similar vectors
    *   Early algorithms struggled to efficiently learn these representations

The increased availability of data and computing power fueled the adoption of neural networks and word embeddings, significantly improving NLP performance.

**2006: launch of Google Translate**

*   The first commercially successful NLP system
*   Utilized statistical models to automatically translate documents

Google Translate demonstrated the practical potential of statistical machine translation and marked a significant milestone in NLP history.

<----------section---------->

### Deep Learning Era

**2010's:**

*   LSTM and CNN became widely adopted for NLP
*   The availability of large text corpora enabled the training of increasingly complex models

The deep learning era brought significant advancements in NLP, with LSTMs and CNNs proving highly effective for various tasks.

**Word2Vec (2013):**

*   Efficient Estimation of Word Representations in Vector Space
*   The first algorithm to efficiently learn word embeddings
*   Enables semantic operations with word vector
*   Paved the way for more advanced models such as GloVe, fastText, ELMo, BERT, COLBERT, GPT, ...

Word2Vec revolutionized NLP by enabling the efficient learning of word embeddings, which capture semantic relationships between words.

<----------section---------->

### Deep Learning Era

**Sequence-to-Sequence Models (2014):**

*   Introduction of the encoder-decoder architecture:
    *   **Encoder:** Encodes the input into a context vector
    *   **Decoder:** Decodes the output from the context vector
*   Useful for automatic translation, question answering, text summarization, text generation, ...

**Example:**

```
The red house -> Context vector [0.3, 0.6, -0.2, ..., 0.1] -> La casa rossa
```

Sequence-to-sequence models provided a powerful framework for tasks such as machine translation, enabling the translation of entire sequences of words.

<----------section---------->

### Virtual Assistants

A Virtual Assistant performs a range of tasks or services based on user input in natural language.

Many VA were launched in 2010's:

*   2011: Siri launched by Apple on iOS devices
*   2014: Cortana introduced by Microsoft for Windows Phone
*   2014: Alexa launched by Amazon with the Echo, pioneering voice-controlled smart home
*   2015: Google Assistant introduced, integrating voice interaction with Android and Google Home

These virtual assistants brought NLP to the mainstream, enabling voice-controlled interactions and a wide range of automated tasks.

<----------section---------->

### Deep Learning Era

**Transformer (2017):**

*   **Attention Is All You Need**
*   Integration of attention mechanisms
*   Allows a greater passage of information between the decoder and the encoder
*   Defined and adopted by Google for the translator
*   It remains the dominant architecture in NLP today

*Diagram of Transformer Architecture*

The Transformer architecture, with its attention mechanism, marked a significant breakthrough in NLP, enabling models to capture long-range dependencies and achieve state-of-the-art performance.

<----------section---------->

### Large Language Models

After transformers, the next step was scaling...

*   LLM leverage extensive data and computational power to understand and generate human-like text

*   List of LLMs: GPT-4, ChatGPT, InstructGPT, Codex, Flan-PaLM, LLaMA, BLOOM, OPT, UL2, PaLM, Gopher, Chinchilla, Titan, Jurassic-1, Ernie 3.0, PanGu, etc.*

LLMs represent the latest advancement in NLP, leveraging massive datasets and computational power to achieve unprecedented levels of language understanding and generation.

### LLM Applications

*   **Text Generation:** Producing articles, stories, and creative writing
*   **Machine Translation:** Translating between languages
*   **Chatbots:** Engaging in human-like conversations for customer support and interaction
*   **Code Generation:** Generating and suggesting code snippets, completing code, and assisting with programming tasks
*   **Question Answering:** Providing answers based on a given context or database
*   **Text Summarization:** Condensing long documents into concise summaries
*   **Writing Assistance:** Generating and completing text, improving grammar, and enhancing style

LLMs have enabled significant advancements in a wide array of NLP applications.

<----------section---------->

### Multimodal LLM

Integrate and process multiple types of data

*   **Image-to-Text:** generating descriptive text from images (CLIP)
*   **Text-to-Image:** creating images based on textual descriptions (DALL-E)
*   **Audio-to-Text:** converting spoken language into written text (Whisper)
*   **Text-to-Audio:** composing or generating audio, such as music, from textual descriptions (Jukebox)

Multimodal LLMs are expanding the boundaries of NLP by integrating and processing multiple data types, enabling richer and more versatile applications.

<----------section---------->

### Multimodal LLM

Integrate and process multiple types of data

*   **Video-to-Text:** Generating textual descriptions or summaries from video content (VideoBERT)
*   **Text-to-Video:** Video content from textual descriptions (Sora)

Example Prompt: Photorealistic closeup video of two pirate ships battling each other as they sail inside a cup of coffee

Multimodal models are extending their influence into processing and generating video content, leading to advancements in video understanding and generation capabilities.

## References

*   Natural Language Processing IN ACTION: Understanding, analyzing, and generating text with Python, Chapter 1

This reference provides a starting point for further exploration of NLP concepts and techniques.
