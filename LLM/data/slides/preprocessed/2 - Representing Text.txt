
2.4.2 The PennTreebankTokenizer
The PennTreebankTokenizer is a tokenizer that was developed by the Penn
Treebank project, which was a large-scale effort to create a corpus of
annotated text for natural language processing research. The PennTreebank
Tokenizer is a very popular tokenizer for English text.
2.4.3 The TweetTokenizer
The TweetTokenizer is a tokenizer that was developed by the Stanford
NLP group for tokenizing tweets. It is a very popular tokenizer for
Twitter text.
2.4.4 The spaCy Tokenizer
The spaCy tokenizer is a state-of-the-art tokenizer for English text. It
is a very popular tokenizer for English text.
2.4.5 The Stanford CoreNLP Tokenizer
The Stanford CoreNLP Tokenizer is a tokenizer that was developed by the
Stanford NLP group for tokenizing text in many languages. It is a very
popular tokenizer for many languages.
2.4.6 The HuggingFace Tokenizer
The HuggingFace Tokenizer is a tokenizer that was developed by the
HuggingFace team for tokenizing text in many languages. It is a very
popular tokenizer for many languages.
2.4.7 The Simple Tokenizer
The simplest way to tokenize a sentence is to use whitespace within a string.
This is the tokenizer that you will use in this book.
2.5 One-hot encoding
One-hot encoding is a way to represent words as a matrix of numbers.
Each row of the matrix represents a word, and each column represents a
possible token. If a particular token is present in a word, the value in the
corresponding cell of the matrix is 1, otherwise it is 0.
2.6 Vectors of tokens
Now that you have broken your text into tokens of meaning, what do you do
with them? How can you convert them to numbers that will be meaningful to
the machine? The simplest most basic thing to do would be to detect whether
a particular token you are interested in was present or not. You could hard-
code the logic to check for important tokens, called a keywords.
2.6.1 One-hot Vectors
Now that you ve successfully