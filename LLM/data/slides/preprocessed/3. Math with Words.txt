 and
powerful tools in the NLP toolkit.


Trasforma il seguente testo rendendolo più chiaro e leggibile, e arricchislo con informazioni rilevanti recuperate dal libro. Mantieni il significato originale e approfondisci gli argomenti.

Natural Language Processing and Large Language Models
Corso di Laurea Magistrale in Ingegneria Informatica
Lesson 3
Math with Words
Nicola Capuano and Antonio Greco
DIEM – University of Salerno

Outline
- Term Frequency
- Vector Space Model
- TF-IDF
- Building a Search Engine

Term Frequency
- Bag of Words: A vector space model of text
  - One-hot encode each word in a text and combine one-hot vectors
  - Binary BoW: one-hot vectors are combined with the OR operation
  - Standard BoW: one-hot vectors are summed
  - Term Frequency (TF): number of occurrences of each word in the text
    Assumption: The more times a word occurs, the more meaning it contributes to that document

Calculating TF
- Example: In document A the word "dog" appears 3 times, in document B the word "dog" appears 100 times. Is the word "dog" more important for document A or B?
- Additional information: Document A is a 30-word email to a veterinarian, Document B is the novel "War & Peace" (approx. 580,000 words)
- Normalized TF: Normalized (weighted) TF is the word count normalized by the document length

Vector Space Model
- NLTK Corpora: Natural Language Toolkit includes several text corpora
  - They can be used to train and test NLP algorithms
  - It has a package to easily access corpus data
  - https://www.nltk.org/howto/corpus.html Reuters 21578 corpus: Widely used for NLP and text classification

Corpus Processing
- Inefficient: spaCy extracts a lot of information from text, but we only need tokenization