{
  "question_id": 15,
  "section_index": 3,
  "question": "Explain the concept of \"Parameter Efficient Fine Tuning\" in the context of LLMs and why it's important.",
  "response": "Parameter-Efficient Fine-Tuning (PEFT) methods reduce the computational and storage burden of full fine-tuning by modifying only a small fraction of the model's parameters. This makes fine-tuning large LLMs feasible for resource-constrained environments and applications requiring frequent model updates. PEFT techniques include Low-Rank Adaptation (LoRA), Adapters, and Prefix Tuning. LoRA injects trainable rank decomposition matrices into each layer of the Transformer model, allowing efficient fine-tuning with minimal parameter updates. Adapters are small, task-specific modules inserted within the Transformer layers, enabling fine-tuning without modifying the original model weights and are useful for multi-task learning. Prefix Tuning prepends a sequence of trainable prefix tokens to the input sequence, influencing the model's attention mechanism and guiding its output generation without altering the original weights.",
  "response_time": 2.096891164779663,
  "timestamp": "2025-03-13T17:27:02.282133"
}