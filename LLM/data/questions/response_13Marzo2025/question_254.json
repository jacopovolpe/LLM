{
  "question_id": 254,
  "section_index": 51,
  "question": "Which text corpora are used for pre-training BERT?",
  "response": "BERT was pre-trained using a massive text corpus consisting of BooksCorpus and English Wikipedia.",
  "response_time": 1.5772390365600586,
  "timestamp": "2025-03-13T17:56:54.264946"
}