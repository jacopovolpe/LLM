{
  "question_id": 12,
  "section_index": 3,
  "question": "Explain the concept of \"Self-Attention\" in the context of Transformers and how it differs from traditional attention mechanisms.",
  "response": "The Transformer architecture uses a self-attention mechanism, which allows the model to weigh the importance of different words in the input sequence when encoding a specific word and understand relationships between words within the same sentence. In the sentence \"The animal didn’t cross the street because it was too wide,\" self-attention helps the model associate \"it\" with \"the street\" rather than \"the animal\". The attention mechanism employs three matrices: Query (Q), Key (K), and Value (V), derived from the input embeddings through linear transformations. The attention weights are calculated using scaled dot-product attention, which measures the similarity between query and key vectors. These weights are then used to create a weighted sum of the value vectors, producing a context-aware representation of the input sequence, and the scaling factor (1/√dk) prevents extremely small gradients during training, especially with high-dimensional vectors. The core innovation of the Transformer model lies in its use of self-attention, a mechanism that allows the model to consider the relationships between all words in a sequence simultaneously, unlike RNNs, which process sequences sequentially. The parallel processing capabilities of transformers, coupled with their ability to handle long-range dependencies, have made them a cornerstone of modern NLP.",
  "response_time": 2.2725861072540283,
  "timestamp": "2025-03-13T17:26:35.031417"
}