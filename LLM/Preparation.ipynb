{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGING_FACE_TOKEN = \"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\"\n",
    "GEMINI_TOKEN = \"AIzaSyArDcTFUTzztpgCIlogXSYQwBhUieZxv7Y\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a56b0c",
   "metadata": {},
   "source": [
    "## **1* Estrazione del testo dal libro*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, output_txt_path):\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as pdf_file:\n",
    "            reader = PyPDF2.PdfReader(pdf_file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "        \n",
    "        with open(output_txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            txt_file.write(text)\n",
    "        \n",
    "        print(f\"Testo estratto e salvato in {output_txt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante l'estrazione del testo: {e}\")\n",
    "\n",
    "# Esempio di utilizzo\n",
    "pdf_file_path = \"data/book.pdf\"  \n",
    "output_text_path = \"data/book.txt\"\n",
    "extract_text_from_pdf(pdf_file_path, output_text_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07a3a4",
   "metadata": {},
   "source": [
    "## **2* Inizializzazione del Retriever (FAISS)** üîç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20161b5",
   "metadata": {},
   "source": [
    "üìå FAISS: Cos'√®, Come Funziona e a Cosa Serve\n",
    "FAISS (Facebook AI Similarity Search) √® una libreria sviluppata da Meta AI per eseguire ricerche veloci su grandi set di dati vettoriali. √à ottimizzata per trovare il Nearest Neighbor (NN) in spazi ad alta dimensionalit√†, rendendola ideale per compiti di similarity search come la ricerca di documenti, immagini o frasi simili.\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        <b>Generazione degli Embeddings:</b>\n",
    "        Un modello NLP (es. Sentence Transformers) converte il testo in vettori numerici.\n",
    "        Ogni documento viene trasformato in una rappresentazione densa in uno spazio vettoriale.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Creazione dell‚ÄôIndice FAISS:</b>\n",
    "        FAISS memorizza questi vettori in una struttura dati ottimizzata per ricerche veloci.\n",
    "        Supporta diversi tipi di indicizzazione (es. Flat, HNSW, IVF) a seconda delle esigenze.\n",
    "    </li>\n",
    "    <li>\n",
    "    <b>Ricerca e Recupero:</b>\n",
    "    Un nuovo testo viene trasformato in un embedding.\n",
    "    FAISS trova i vettori pi√π vicini nel database (nearest neighbors) restituendo i documenti pi√π simili.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c06c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever FAISS inizializzato e salvato.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "document_path = \"data/book.txt\"\n",
    "loader = TextLoader(document_path, encoding=\"utf-8\")  \n",
    "doc_loader = loader.load()\n",
    "\n",
    "\n",
    "# Split del testo per migliorare la ricerca\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=150)\n",
    "split_docs = text_splitter.split_documents(doc_loader)\n",
    "\n",
    "# Creazione degli embeddings con un modello open-source\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "#embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "# Creazione del database FAISS\n",
    "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
    "\n",
    "# Salviamo il database FAISS\n",
    "vectorstore.save_local(\"faiss_index__all-MiniLM-L6-v2\")\n",
    "print(\"Retriever FAISS inizializzato e salvato.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab885cc7",
   "metadata": {},
   "source": [
    "## *3*  Preprocessing delle informazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a17822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=GEMINI_TOKEN)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "\n",
    "def call_llm(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374dec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 15 0 (offset 0)\n",
      "Ignoring wrong pointing object 25 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 47 0 (offset 0)\n",
      "Ignoring wrong pointing object 49 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 55 0 (offset 0)\n",
      "Ignoring wrong pointing object 64 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando: data/slides/original\\0. Course Introduction.pdf\n",
      "Salvato: data/merged/preprocessed_by_gemini\\0. Course Introduction.txt\n",
      "Processando: data/slides/original\\09. Transformers I.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n",
      "Ignoring wrong pointing object 41 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 61 0 (offset 0)\n",
      "Ignoring wrong pointing object 63 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 67 0 (offset 0)\n",
      "Ignoring wrong pointing object 69 0 (offset 0)\n",
      "Ignoring wrong pointing object 74 0 (offset 0)\n",
      "Ignoring wrong pointing object 164 0 (offset 0)\n",
      "Ignoring wrong pointing object 166 0 (offset 0)\n",
      "Ignoring wrong pointing object 168 0 (offset 0)\n",
      "Ignoring wrong pointing object 170 0 (offset 0)\n",
      "Ignoring wrong pointing object 182 0 (offset 0)\n",
      "Ignoring wrong pointing object 196 0 (offset 0)\n",
      "Ignoring wrong pointing object 204 0 (offset 0)\n",
      "Ignoring wrong pointing object 206 0 (offset 0)\n",
      "Ignoring wrong pointing object 208 0 (offset 0)\n",
      "Ignoring wrong pointing object 222 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvato: data/merged/preprocessed_by_gemini\\09. Transformers I.txt\n",
      "Processando: data/slides/original\\1. NLP Overview.pdf\n",
      "Salvato: data/merged/preprocessed_by_gemini\\1. NLP Overview.txt\n",
      "Processando: data/slides/original\\10. Transformers II.pdf\n",
      "Salvato: data/merged/preprocessed_by_gemini\\10. Transformers II.txt\n",
      "Processando: data/slides/original\\11. From Transformers to LLMs.pdf\n",
      "Salvato: data/merged/preprocessed_by_gemini\\11. From Transformers to LLMs.txt\n",
      "Processando: data/slides/original\\12. HuggingFace.pdf\n",
      "Salvato: data/merged/preprocessed_by_gemini\\12. HuggingFace.txt\n",
      "Processando: data/slides/original\\13. Encoder-only Transformers.pdf\n",
      "Salvato: data/merged/preprocessed_by_gemini\\13. Encoder-only Transformers.txt\n",
      "Processando: data/slides/original\\14. Decoder-only Transformers.pdf\n",
      "Salvato: data/merged/preprocessed_by_gemini\\14. Decoder-only Transformers.txt\n",
      "Processando: data/slides/original\\15. Encoder-Decoder Transformers.pdf\n",
      "Salvato: data/merged/preprocessed_by_gemini\\15. Encoder-Decoder Transformers.txt\n",
      "Processando: data/slides/original\\16. Final Project.pdf\n",
      "Salvato: data/merged/preprocessed_by_gemini\\16. Final Project.txt\n",
      "Processando: data/slides/original\\17. Fine tuning.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n",
      "Ignoring wrong pointing object 33 0 (offset 0)\n",
      "Ignoring wrong pointing object 35 0 (offset 0)\n",
      "Ignoring wrong pointing object 37 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 44 0 (offset 0)\n",
      "Ignoring wrong pointing object 46 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 55 0 (offset 0)\n",
      "Ignoring wrong pointing object 60 0 (offset 0)\n",
      "Ignoring wrong pointing object 62 0 (offset 0)\n",
      "Ignoring wrong pointing object 64 0 (offset 0)\n",
      "Ignoring wrong pointing object 81 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 99 0 (offset 0)\n",
      "Ignoring wrong pointing object 101 0 (offset 0)\n",
      "Ignoring wrong pointing object 103 0 (offset 0)\n",
      "Ignoring wrong pointing object 105 0 (offset 0)\n",
      "Ignoring wrong pointing object 107 0 (offset 0)\n",
      "Ignoring wrong pointing object 117 0 (offset 0)\n",
      "Ignoring wrong pointing object 134 0 (offset 0)\n",
      "Ignoring wrong pointing object 152 0 (offset 0)\n",
      "Ignoring wrong pointing object 154 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 172 0 (offset 0)\n",
      "Ignoring wrong pointing object 180 0 (offset 0)\n",
      "Ignoring wrong pointing object 182 0 (offset 0)\n",
      "Ignoring wrong pointing object 201 0 (offset 0)\n",
      "Ignoring wrong pointing object 218 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvato: data/merged/preprocessed_by_gemini\\17. Fine tuning.txt\n",
      "Processando: data/slides/original\\18. Prompt Engineering.pdf\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Resource has been exhausted (e.g. check quota).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m input_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/slides/original/\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m     63\u001b[0m output_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/merged/preprocessed_by_gemini\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m---> 64\u001b[0m \u001b[43mprocess_pdfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 54\u001b[0m, in \u001b[0;36mprocess_pdfs\u001b[1;34m(input_directory, output_directory)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     53\u001b[0m additional_info \u001b[38;5;241m=\u001b[39m retrieve_relevant_info(extracted_text, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 54\u001b[0m improved_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_better_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_directory, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(pdf_path)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m, in \u001b[0;36mgenerate_better_text\u001b[1;34m(text, additional_info)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Genera un testo migliorato e approfondito basandosi sul contenuto estratto.\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRewrite the provided text to make it clearer, more detailed, and comprehensive. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyze the main topics discussed, integrate relevant insights, and enrich the content with additional details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdditional Information:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m additional_info\n\u001b[0;32m     35\u001b[0m )\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mcall_llm\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_llm\u001b[39m(prompt):\n\u001b[1;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    332\u001b[0m             request,\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pypdf\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Carica il database FAISS\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"data/faiss_index/ALL_faiss_index__all-MiniLM-L6-v2/\",\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Estrae il testo da un file PDF.\"\"\"\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader = pypdf.PdfReader(f)\n",
    "        return \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "\n",
    "def retrieve_relevant_info(text, k=5):\n",
    "    \"\"\"Recupera informazioni pertinenti dal database FAISS.\"\"\"\n",
    "    docs = vectorstore.similarity_search(text, k=k)\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "def generate_better_text(text, additional_info):\n",
    "    \"\"\"Genera un testo migliorato e approfondito basandosi sul contenuto estratto.\"\"\"\n",
    "    prompt = (\n",
    "        \"Rewrite the provided text to make it clearer, more detailed, and comprehensive. \"\n",
    "        \"Analyze the main topics discussed, integrate relevant insights, and enrich the content with additional details. \"\n",
    "        \"Ensure that the resulting text is structured naturally and flows smoothly, without explicit references to the original sources. \"\n",
    "        \"Maintain the original meaning while incorporating pertinent explanations and context.\\n\\n\"\n",
    "        \"Original Text:\\n\" + text + \"\\n\\n\"\n",
    "        \"Additional Information:\\n\" + additional_info\n",
    "    )\n",
    "\n",
    "    return call_llm(prompt)\n",
    "\n",
    "\n",
    "\n",
    "def process_pdfs(input_directory, output_directory):\n",
    "    \"\"\"Processa tutti i PDF in una directory e salva i testi migliorati e approfonditi.\"\"\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    pdf_files = sorted(glob.glob(os.path.join(input_directory, \"*.pdf\")))  # Ordina alfabeticamente\n",
    "    skip_first = 11\n",
    "    cont = 0\n",
    "    for pdf_path in pdf_files:\n",
    "        cont += 1\n",
    "        if cont < skip_first:\n",
    "            continue    \n",
    "        \n",
    "        print(f\"Processando: {pdf_path}\")\n",
    "        extracted_text = extract_text_from_pdf(pdf_path)\n",
    "        if not extracted_text.strip():\n",
    "            print(f\"Nessun testo estratto da {pdf_path}\")\n",
    "            continue\n",
    "        \n",
    "        additional_info = retrieve_relevant_info(extracted_text, k=3)\n",
    "        improved_text = generate_better_text(extracted_text, additional_info)\n",
    "        output_path = os.path.join(output_directory, os.path.basename(pdf_path).replace(\".pdf\", \".txt\"))\n",
    "        \n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(improved_text)\n",
    "        print(f\"Salvato: {output_path}\")\n",
    "\n",
    "\n",
    "input_directory = \"data/slides/original/\" \n",
    "output_directory = \"data/merged/preprocessed_by_gemini\" \n",
    "process_pdfs(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc1ed2a",
   "metadata": {},
   "source": [
    "## *4* Unisco in un unico File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fe5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def merge_text_files(folder_path, output_file):\n",
    "\n",
    "    text_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".txt\")])\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for file_name in text_files:\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                outfile.write(infile.read() + '\\n')  \n",
    "    \n",
    "    print(f\"Unione completata: {output_file}\")\n",
    "\n",
    "# Esempio di utilizzo\n",
    "folder_path = \"data/merged/preprocessed_by_gemini\"  \n",
    "output_file = \"data/all_preprocessed_by_gemini.txt\"  \n",
    "merge_text_files(folder_path, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4810b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "document_path = \"data/all_preprocessed_by_gemini.txt\"\n",
    "loader = TextLoader(document_path, encoding=\"utf-8\")  \n",
    "doc_loader = loader.load()\n",
    "\n",
    "\n",
    "# Split del testo per migliorare la ricerca\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_docs = text_splitter.split_documents(doc_loader)\n",
    "\n",
    "# Creazione degli embeddings con un modello open-source\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "#embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "# Creazione del database FAISS\n",
    "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
    "\n",
    "# Salviamo il database FAISS\n",
    "vectorstore.save_local(\"ALL_faiss_index__all-MiniLM-L6-v2\")\n",
    "print(\"Retriever FAISS inizializzato e salvato.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b242a9ac",
   "metadata": {},
   "source": [
    "## *5* RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404cddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Configurazione del modello\n",
    "MODEL_LLM_PATH = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "API_URL = f\"https://api-inference.huggingface.co/models/{MODEL_LLM_PATH}\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {HUGGING_FACE_TOKEN}\"}\n",
    "\n",
    "# Caricamento embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(\"ALL_faiss_index__all-MiniLM-L6-v2\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "def generate_response(question, debug = False):\n",
    "    docs = vectorstore.similarity_search(question, k=10)\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an AI assistant using Retrieval-Augmented Generation (RAG). \"\n",
    "        \"Use the following context to answer the question. If the answer is not in the context, say you don't know. \" \n",
    "        \"Give discursive answers\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        \"-----END_QUESTION-----\"\n",
    "    )\n",
    "\n",
    "    payload = {\"inputs\": prompt}\n",
    "    response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"API Response Code: {response.status_code}\")\n",
    "        print(f\"Total Response: \\n{response}\\n\\n\\n\\n\")\n",
    "        print(f\"API Raw Response: {response.text}\")\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return f\"Errore API ({response.status_code}): {response.text}\"\n",
    "    \n",
    "    try:\n",
    "        response_json = response.json()\n",
    "        generated_text = response_json[0].get(\"generated_text\", \"Errore nella generazione della risposta\")\n",
    "        clean_response = generated_text.split(\"-----END_QUESTION-----\")[-1].strip() \n",
    "        return clean_response\n",
    "\n",
    "      \n",
    "    except requests.exceptions.JSONDecodeError:\n",
    "        return \"Errore nel parsing della risposta JSON\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c53837",
   "metadata": {},
   "source": [
    "#### ESEMPIO DI UTILIZZO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e45df07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardrails are crucial mechanisms designed to mitigate risks associated with Large Language Models (LLMs) by implementing policies and technical solutions. They ensure that LLMs generate outputs that are safe, accurate, and contextually relevant, fostering trust and enabling reliable real-world applications.\n",
      "\n",
      "Without guardrails, LLMs can unintentionally perpetuate harmful stereotypes, generate misinformation, or produce outputs that are illegal or unethical. They may also be susceptible to adversarial attacks, where users deliberately try to circumvent safety measures, further highlighting the importance of robust guardrails.\n",
      "\n",
      "There are several types of guardrails, including ethical guardrails and operational guardrails. Ethical guardrails focus on avoiding bias, misinformation, and ensuring fairness in the LLM's responses. Operational guardrails align outputs with business or user objectives and can incite politeness, help, and consistency with brand guidelines.\n",
      "\n",
      "Several techniques can be employed to add guardrails to LLMs, including using frameworks like Guardrails AI or LangChain. It's also important to continuously monitor, adapt to evolving adversarial techniques, and combine multiple techniques for a robust defense against unexpected outputs. Leveraging established NLU techniques and quantifiable accuracy metrics also provides more reliable and consistent guardrail performance.\n",
      "\n",
      "The limitation of static embeddings such as Word2Vec, GloVe, and FastText is that they represent each word with a single vector, disregarding context. Contextual embeddings, like ELMo and BERT, generate word vectors based on surrounding context to address this issue. However, challenges like polysemy, semantic drift, perpetuation of social biases, out-of-vocabulary words, and a lack of transparency and interpretability continue to present difficulties.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "response = generate_response(\"Talk me about Gardrails\", debug = False)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
